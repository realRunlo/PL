[
    {
        "label": "generators",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "literals",
        "importPath": "lib2to3.pgen2",
        "description": "lib2to3.pgen2",
        "isExtraImport": true,
        "detail": "lib2to3.pgen2",
        "documentation": {}
    },
    {
        "label": "literals",
        "importPath": "lib2to3.pgen2",
        "description": "lib2to3.pgen2",
        "isExtraImport": true,
        "detail": "lib2to3.pgen2",
        "documentation": {}
    },
    {
        "label": "ply.lex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "ply.yacc",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "tokens",
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "isExtraImport": true,
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "literals",
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "isExtraImport": true,
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "Macro",
        "kind": 6,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "class Macro(object):\n    def __init__(self,name,value,arglist=None,variadic=False):\n        self.name = name\n        self.value = value\n        self.arglist = arglist\n        self.variadic = variadic\n        if variadic:\n            self.vararg = arglist[-1]\n        self.source = None\n# ------------------------------------------------------------------",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "Preprocessor",
        "kind": 6,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "class Preprocessor(object):\n    def __init__(self,lexer=None):\n        if lexer is None:\n            lexer = lex.lexer\n        self.lexer = lexer\n        self.macros = { }\n        self.path = []\n        self.temp_path = []\n        # Probe the lexer for selected tokens\n        self.lexprobe()",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_WS",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_WS(t):\n    r'\\s+'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\nt_CPP_POUND = r'\\#'\nt_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "CPP_INTEGER",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_STRING",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Character constant 'c' or L'c'\ndef t_CPP_CHAR(t):\n    r'(L)?\\'([^\\\\\\n]|(\\\\(.|\\n)))*?\\''\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Comment",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_CHAR",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_CHAR(t):\n    r'(L)?\\'([^\\\\\\n]|(\\\\(.|\\n)))*?\\''\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Comment\ndef t_CPP_COMMENT1(t):\n    r'(/\\*(.|\\n)*?\\*/)'\n    ncr = t.value.count(\"\\n\")\n    t.lexer.lineno += ncr\n    # replace with one space or a number of '\\n'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_COMMENT1",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_COMMENT1(t):\n    r'(/\\*(.|\\n)*?\\*/)'\n    ncr = t.value.count(\"\\n\")\n    t.lexer.lineno += ncr\n    # replace with one space or a number of '\\n'\n    t.type = 'CPP_WS'; t.value = '\\n' * ncr if ncr else ' '\n    return t\n# Line comment\ndef t_CPP_COMMENT2(t):\n    r'(//.*?(\\n|$))'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_COMMENT2",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_COMMENT2(t):\n    r'(//.*?(\\n|$))'\n    # replace with '/n'\n    t.type = 'CPP_WS'; t.value = '\\n'\n    return t\ndef t_error(t):\n    t.type = t.value[0]\n    t.value = t.value[0]\n    t.lexer.skip(1)\n    return t",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_error",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_error(t):\n    t.type = t.value[0]\n    t.value = t.value[0]\n    t.lexer.skip(1)\n    return t\nimport re\nimport copy\nimport time\nimport os.path\n# -----------------------------------------------------------------------------",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "trigraph",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def trigraph(input):\n    return _trigraph_pat.sub(lambda g: _trigraph_rep[g.group()[-1]],input)\n# ------------------------------------------------------------------\n# Macro object\n#\n# This object holds information about preprocessor macros\n#\n#    .name      - Macro name (string)\n#    .value     - Macro value (a list of tokens)\n#    .arglist   - List of argument names",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "tokens = (\n   'CPP_ID','CPP_INTEGER', 'CPP_FLOAT', 'CPP_STRING', 'CPP_CHAR', 'CPP_WS', 'CPP_COMMENT1', 'CPP_COMMENT2', 'CPP_POUND','CPP_DPOUND'\n)\nliterals = \"+-*/%|&~^<>=!?()[]{}.,;:\\\\\\'\\\"\"\n# Whitespace\ndef t_CPP_WS(t):\n    r'\\s+'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\nt_CPP_POUND = r'\\#'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "literals",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "literals = \"+-*/%|&~^<>=!?()[]{}.,;:\\\\\\'\\\"\"\n# Whitespace\ndef t_CPP_WS(t):\n    r'\\s+'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\nt_CPP_POUND = r'\\#'\nt_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_POUND",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_POUND = r'\\#'\nt_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_DPOUND",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_ID",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_INTEGER",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Character constant 'c' or L'c'\ndef t_CPP_CHAR(t):",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_FLOAT",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Character constant 'c' or L'c'\ndef t_CPP_CHAR(t):\n    r'(L)?\\'([^\\\\\\n]|(\\\\(.|\\n)))*?\\''\n    t.lexer.lineno += t.value.count(\"\\n\")",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "_trigraph_pat",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "_trigraph_pat = re.compile(r'''\\?\\?[=/\\'\\(\\)\\!<>\\-]''')\n_trigraph_rep = {\n    '=':'#',\n    '/':'\\\\',\n    \"'\":'^',\n    '(':'[',\n    ')':']',\n    '!':'|',\n    '<':'{',\n    '>':'}',",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "_trigraph_rep",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "_trigraph_rep = {\n    '=':'#',\n    '/':'\\\\',\n    \"'\":'^',\n    '(':'[',\n    ')':']',\n    '!':'|',\n    '<':'{',\n    '>':'}',\n    '-':'~'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_COMMENT",
        "kind": 2,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "def t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t\n# Comment (C++-Style)\ndef t_CPPCOMMENT(t):\n    r'//.*\\n'\n    t.lexer.lineno += 1\n    return t",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_CPPCOMMENT",
        "kind": 2,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "def t_CPPCOMMENT(t):\n    r'//.*\\n'\n    t.lexer.lineno += 1\n    return t",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "tokens = [\n    # Literals (identifier, integer constant, float constant, string constant, char const)\n    'ID', 'TYPEID', 'INTEGER', 'FLOAT', 'STRING', 'CHARACTER',\n    # Operators (+,-,*,/,%,|,&,~,^,<<,>>, ||, &&, !, <, <=, >, >=, ==, !=)\n    'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'MODULO',\n    'OR', 'AND', 'NOT', 'XOR', 'LSHIFT', 'RSHIFT',\n    'LOR', 'LAND', 'LNOT',\n    'LT', 'LE', 'GT', 'GE', 'EQ', 'NE',\n    # Assignment (=, *=, /=, %=, +=, -=, <<=, >>=, &=, ^=, |=)\n    'EQUALS', 'TIMESEQUAL', 'DIVEQUAL', 'MODEQUAL', 'PLUSEQUAL', 'MINUSEQUAL',",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_ID",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_ID = r'[A-Za-z_][A-Za-z0-9_]*'\n# Integer literal\nt_INTEGER = r'\\d+([uU]|[lL]|[uU][lL]|[lL][uU])?'\n# Floating literal\nt_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\nt_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_INTEGER",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_INTEGER = r'\\d+([uU]|[lL]|[uU][lL]|[lL][uU])?'\n# Floating literal\nt_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\nt_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_FLOAT",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\nt_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_STRING",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t\n# Comment (C++-Style)\ndef t_CPPCOMMENT(t):",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_CHARACTER",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t\n# Comment (C++-Style)\ndef t_CPPCOMMENT(t):\n    r'//.*\\n'\n    t.lexer.lineno += 1",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "LexError",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class LexError(Exception):\n    def __init__(self, message, s):\n        self.args = (message,)\n        self.text = s\n# Token class.  This class is used to represent the tokens produced.\nclass LexToken(object):\n    def __str__(self):\n        return 'LexToken(%s,%r,%d,%d)' % (self.type, self.value, self.lineno, self.lexpos)\n    def __repr__(self):\n        return str(self)",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "LexToken",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class LexToken(object):\n    def __str__(self):\n        return 'LexToken(%s,%r,%d,%d)' % (self.type, self.value, self.lineno, self.lexpos)\n    def __repr__(self):\n        return str(self)\n# This object is a stand-in for a logging object created by the\n# logging module.\nclass PlyLogger(object):\n    def __init__(self, f):\n        self.f = f",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "PlyLogger",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class PlyLogger(object):\n    def __init__(self, f):\n        self.f = f\n    def critical(self, msg, *args, **kwargs):\n        self.f.write((msg % args) + '\\n')\n    def warning(self, msg, *args, **kwargs):\n        self.f.write('WARNING: ' + (msg % args) + '\\n')\n    def error(self, msg, *args, **kwargs):\n        self.f.write('ERROR: ' + (msg % args) + '\\n')\n    info = critical",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "NullLogger",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class NullLogger(object):\n    def __getattribute__(self, name):\n        return self\n    def __call__(self, *args, **kwargs):\n        return self\n# -----------------------------------------------------------------------------\n#                        === Lexing Engine ===\n#\n# The following Lexer class implements the lexer runtime.   There are only\n# a few public methods and attributes:",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "Lexer",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class Lexer:\n    def __init__(self):\n        self.lexre = None             # Master regular expression. This is a list of\n                                      # tuples (re, findex) where re is a compiled\n                                      # regular expression and findex is a list\n                                      # mapping regex group numbers to rules\n        self.lexretext = None         # Current regular expression strings\n        self.lexstatere = {}          # Dictionary mapping lexer states to master regexs\n        self.lexstateretext = {}      # Dictionary mapping lexer states to regex strings\n        self.lexstaterenames = {}     # Dictionary mapping lexer states to symbol names",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "LexerReflect",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class LexerReflect(object):\n    def __init__(self, ldict, log=None, reflags=0):\n        self.ldict      = ldict\n        self.error_func = None\n        self.tokens     = []\n        self.reflags    = reflags\n        self.stateinfo  = {'INITIAL': 'inclusive'}\n        self.modules    = set()\n        self.error      = False\n        self.log        = PlyLogger(sys.stderr) if log is None else log",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "get_caller_module_dict",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def get_caller_module_dict(levels):\n    f = sys._getframe(levels)\n    ldict = f.f_globals.copy()\n    if f.f_globals != f.f_locals:\n        ldict.update(f.f_locals)\n    return ldict\n# -----------------------------------------------------------------------------\n# _funcs_to_names()\n#\n# Given a list of regular expression functions, this converts it to a list",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "lex",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def lex(module=None, object=None, debug=False, optimize=False, lextab='lextab',\n        reflags=int(re.VERBOSE), nowarn=False, outputdir=None, debuglog=None, errorlog=None):\n    if lextab is None:\n        lextab = 'lextab'\n    global lexer\n    ldict = None\n    stateinfo  = {'INITIAL': 'inclusive'}\n    lexobj = Lexer()\n    lexobj.lexoptimize = optimize\n    global token, input",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "runmain",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def runmain(lexer=None, data=None):\n    if not data:\n        try:\n            filename = sys.argv[1]\n            f = open(filename)\n            data = f.read()\n            f.close()\n        except IndexError:\n            sys.stdout.write('Reading from standard input (type EOF to end):\\n')\n            data = sys.stdin.read()",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "TOKEN",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def TOKEN(r):\n    def set_regex(f):\n        if hasattr(r, '__call__'):\n            f.regex = _get_regex(r)\n        else:\n            f.regex = r\n        return f\n    return set_regex\n# Alternative spelling of the TOKEN decorator\nToken = TOKEN",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "__tabversion__",
        "kind": 5,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "__tabversion__ = '3.10'\nimport re\nimport sys\nimport types\nimport copy\nimport os\nimport inspect\n# This tuple contains known string types\ntry:\n    # Python 2.6",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "_is_identifier",
        "kind": 5,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "_is_identifier = re.compile(r'^[a-zA-Z0-9_]+$')\n# Exception thrown when invalid token encountered and no default error\n# handler is defined.\nclass LexError(Exception):\n    def __init__(self, message, s):\n        self.args = (message,)\n        self.text = s\n# Token class.  This class is used to represent the tokens produced.\nclass LexToken(object):\n    def __str__(self):",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "Token",
        "kind": 5,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "Token = TOKEN",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "PlyLogger",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class PlyLogger(object):\n    def __init__(self, f):\n        self.f = f\n    def debug(self, msg, *args, **kwargs):\n        self.f.write((msg % args) + '\\n')\n    info = debug\n    def warning(self, msg, *args, **kwargs):\n        self.f.write('WARNING: ' + (msg % args) + '\\n')\n    def error(self, msg, *args, **kwargs):\n        self.f.write('ERROR: ' + (msg % args) + '\\n')",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "NullLogger",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class NullLogger(object):\n    def __getattribute__(self, name):\n        return self\n    def __call__(self, *args, **kwargs):\n        return self\n# Exception raised for yacc-related errors\nclass YaccError(Exception):\n    pass\n# Format the result message that the parser produces when running in debug mode.\ndef format_result(r):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "YaccError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class YaccError(Exception):\n    pass\n# Format the result message that the parser produces when running in debug mode.\ndef format_result(r):\n    repr_str = repr(r)\n    if '\\n' in repr_str:\n        repr_str = repr(repr_str)\n    if len(repr_str) > resultlimit:\n        repr_str = repr_str[:resultlimit] + ' ...'\n    result = '<%s @ 0x%x> (%s)' % (type(r).__name__, id(r), repr_str)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "YaccSymbol",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class YaccSymbol:\n    def __str__(self):\n        return self.type\n    def __repr__(self):\n        return str(self)\n# This class is a wrapper around the objects actually passed to each\n# grammar rule.   Index lookup and assignment actually assign the\n# .value attribute of the underlying YaccSymbol object.\n# The lineno() method returns the line number of a given\n# item (or 0 if not defined).   The linespan() method returns",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "YaccProduction",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class YaccProduction:\n    def __init__(self, s, stack=None):\n        self.slice = s\n        self.stack = stack\n        self.lexer = None\n        self.parser = None\n    def __getitem__(self, n):\n        if isinstance(n, slice):\n            return [s.value for s in self.slice[n]]\n        elif n >= 0:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRParser",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRParser:\n    def __init__(self, lrtab, errorf):\n        self.productions = lrtab.lr_productions\n        self.action = lrtab.lr_action\n        self.goto = lrtab.lr_goto\n        self.errorfunc = errorf\n        self.set_defaulted_states()\n        self.errorok = True\n    def errok(self):\n        self.errorok = True",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "Production",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class Production(object):\n    reduced = 0\n    def __init__(self, number, name, prod, precedence=('right', 0), func=None, file='', line=0):\n        self.name     = name\n        self.prod     = tuple(prod)\n        self.number   = number\n        self.func     = func\n        self.callable = None\n        self.file     = file\n        self.line     = line",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "MiniProduction",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class MiniProduction(object):\n    def __init__(self, str, name, len, func, file, line):\n        self.name     = name\n        self.len      = len\n        self.func     = func\n        self.callable = None\n        self.file     = file\n        self.line     = line\n        self.str      = str\n    def __str__(self):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRItem",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRItem(object):\n    def __init__(self, p, n):\n        self.name       = p.name\n        self.prod       = list(p.prod)\n        self.number     = p.number\n        self.lr_index   = n\n        self.lookaheads = {}\n        self.prod.insert(n, '.')\n        self.prod       = tuple(self.prod)\n        self.len        = len(self.prod)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "GrammarError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class GrammarError(YaccError):\n    pass\nclass Grammar(object):\n    def __init__(self, terminals):\n        self.Productions  = [None]  # A list of all of the productions.  The first\n                                    # entry is always reserved for the purpose of\n                                    # building an augmented grammar\n        self.Prodnames    = {}      # A dictionary mapping the names of nonterminals to a list of all\n                                    # productions of that nonterminal.\n        self.Prodmap      = {}      # A dictionary that is only used to detect duplicate",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "Grammar",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class Grammar(object):\n    def __init__(self, terminals):\n        self.Productions  = [None]  # A list of all of the productions.  The first\n                                    # entry is always reserved for the purpose of\n                                    # building an augmented grammar\n        self.Prodnames    = {}      # A dictionary mapping the names of nonterminals to a list of all\n                                    # productions of that nonterminal.\n        self.Prodmap      = {}      # A dictionary that is only used to detect duplicate\n                                    # productions.\n        self.Terminals    = {}      # A dictionary mapping the names of terminal symbols to a",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "VersionError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class VersionError(YaccError):\n    pass\nclass LRTable(object):\n    def __init__(self):\n        self.lr_action = None\n        self.lr_goto = None\n        self.lr_productions = None\n        self.lr_method = None\n    def read_table(self, module):\n        if isinstance(module, types.ModuleType):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRTable",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRTable(object):\n    def __init__(self):\n        self.lr_action = None\n        self.lr_goto = None\n        self.lr_productions = None\n        self.lr_method = None\n    def read_table(self, module):\n        if isinstance(module, types.ModuleType):\n            parsetab = module\n        else:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LALRError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LALRError(YaccError):\n    pass\n# -----------------------------------------------------------------------------\n#                             == LRGeneratedTable ==\n#\n# This class implements the LR table generation algorithm.  There are no\n# public methods except for write()\n# -----------------------------------------------------------------------------\nclass LRGeneratedTable(LRTable):\n    def __init__(self, grammar, method='LALR', log=None):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRGeneratedTable",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRGeneratedTable(LRTable):\n    def __init__(self, grammar, method='LALR', log=None):\n        if method not in ['SLR', 'LALR']:\n            raise LALRError('Unsupported method %s' % method)\n        self.grammar = grammar\n        self.lr_method = method\n        # Set up the logger\n        if not log:\n            log = NullLogger()\n        self.log = log",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "ParserReflect",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class ParserReflect(object):\n    def __init__(self, pdict, log=None):\n        self.pdict      = pdict\n        self.start      = None\n        self.error_func = None\n        self.tokens     = None\n        self.modules    = set()\n        self.grammar    = []\n        self.error      = False\n        if log is None:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "format_result",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def format_result(r):\n    repr_str = repr(r)\n    if '\\n' in repr_str:\n        repr_str = repr(repr_str)\n    if len(repr_str) > resultlimit:\n        repr_str = repr_str[:resultlimit] + ' ...'\n    result = '<%s @ 0x%x> (%s)' % (type(r).__name__, id(r), repr_str)\n    return result\n# Format stack entries when the parser is running in debug mode\ndef format_stack_entry(r):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "format_stack_entry",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def format_stack_entry(r):\n    repr_str = repr(r)\n    if '\\n' in repr_str:\n        repr_str = repr(repr_str)\n    if len(repr_str) < 16:\n        return repr_str\n    else:\n        return '<%s @ 0x%x>' % (type(r).__name__, id(r))\n# Panic mode error recovery support.   This feature is being reworked--much of the\n# code here is to offer a deprecation/backwards compatible transition",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "errok",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def errok():\n    warnings.warn(_warnmsg)\n    return _errok()\ndef restart():\n    warnings.warn(_warnmsg)\n    return _restart()\ndef token():\n    warnings.warn(_warnmsg)\n    return _token()\n# Utility function to call the p_error() function with some deprecation hacks",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "restart",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def restart():\n    warnings.warn(_warnmsg)\n    return _restart()\ndef token():\n    warnings.warn(_warnmsg)\n    return _token()\n# Utility function to call the p_error() function with some deprecation hacks\ndef call_errorfunc(errorfunc, token, parser):\n    global _errok, _token, _restart\n    _errok = parser.errok",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "token",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def token():\n    warnings.warn(_warnmsg)\n    return _token()\n# Utility function to call the p_error() function with some deprecation hacks\ndef call_errorfunc(errorfunc, token, parser):\n    global _errok, _token, _restart\n    _errok = parser.errok\n    _token = parser.token\n    _restart = parser.restart\n    r = errorfunc(token)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "call_errorfunc",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def call_errorfunc(errorfunc, token, parser):\n    global _errok, _token, _restart\n    _errok = parser.errok\n    _token = parser.token\n    _restart = parser.restart\n    r = errorfunc(token)\n    try:\n        del _errok, _token, _restart\n    except NameError:\n        pass",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "rightmost_terminal",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def rightmost_terminal(symbols, terminals):\n    i = len(symbols) - 1\n    while i >= 0:\n        if symbols[i] in terminals:\n            return symbols[i]\n        i -= 1\n    return None\n# -----------------------------------------------------------------------------\n#                           === GRAMMAR CLASS ===\n#",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "digraph",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def digraph(X, R, FP):\n    N = {}\n    for x in X:\n        N[x] = 0\n    stack = []\n    F = {}\n    for x in X:\n        if N[x] == 0:\n            traverse(x, N, stack, F, X, R, FP)\n    return F",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "traverse",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def traverse(x, N, stack, F, X, R, FP):\n    stack.append(x)\n    d = len(stack)\n    N[x] = d\n    F[x] = FP(x)             # F(X) <- F'(x)\n    rel = R(x)               # Get y's related to x\n    for y in rel:\n        if N[y] == 0:\n            traverse(y, N, stack, F, X, R, FP)\n        N[x] = min(N[x], N[y])",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "get_caller_module_dict",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def get_caller_module_dict(levels):\n    f = sys._getframe(levels)\n    ldict = f.f_globals.copy()\n    if f.f_globals != f.f_locals:\n        ldict.update(f.f_locals)\n    return ldict\n# -----------------------------------------------------------------------------\n# parse_grammar()\n#\n# This takes a raw grammar rule string and parses it into production data",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "parse_grammar",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def parse_grammar(doc, file, line):\n    grammar = []\n    # Split the doc string into lines\n    pstrings = doc.splitlines()\n    lastp = None\n    dline = line\n    for ps in pstrings:\n        dline += 1\n        p = ps.split()\n        if not p:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "yacc",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def yacc(method='LALR', debug=yaccdebug, module=None, tabmodule=tab_module, start=None,\n         check_recursion=True, optimize=False, write_tables=True, debugfile=debug_file,\n         outputdir=None, debuglog=None, errorlog=None, picklefile=None):\n    if tabmodule is None:\n        tabmodule = tab_module\n    # Reference to the parsing method of the last built parser\n    global parse\n    # If pickling is enabled, table files are not created\n    if picklefile:\n        write_tables = 0",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "__tabversion__",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "__tabversion__ = '3.10'\n#-----------------------------------------------------------------------------\n#                     === User configurable parameters ===\n#\n# Change these to modify the default behavior of yacc (if you wish)\n#-----------------------------------------------------------------------------\nyaccdebug   = True             # Debugging mode.  If set, yacc generates a\n                               # a 'parser.out' file in the current directory\ndebug_file  = 'parser.out'     # Default name of the debugging file\ntab_module  = 'parsetab'       # Default name of the table module",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "error_count",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "error_count = 3                # Number of symbols that must be shifted to leave recovery mode\nyaccdevel   = False            # Set to True if developing yacc.  This turns off optimized\n                               # implementations of certain functions.\nresultlimit = 40               # Size limit of results when running in debug mode.\npickle_protocol = 0            # Protocol to use when writing pickle files\n# String type-checking compatibility\nif sys.version_info[0] < 3:\n    string_types = basestring\nelse:\n    string_types = str",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "resultlimit",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "resultlimit = 40               # Size limit of results when running in debug mode.\npickle_protocol = 0            # Protocol to use when writing pickle files\n# String type-checking compatibility\nif sys.version_info[0] < 3:\n    string_types = basestring\nelse:\n    string_types = str\nMAXINT = sys.maxsize\n# This object is a stand-in for a logging object created by the\n# logging module.   PLY will use this by default to create things",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "pickle_protocol",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "pickle_protocol = 0            # Protocol to use when writing pickle files\n# String type-checking compatibility\nif sys.version_info[0] < 3:\n    string_types = basestring\nelse:\n    string_types = str\nMAXINT = sys.maxsize\n# This object is a stand-in for a logging object created by the\n# logging module.   PLY will use this by default to create things\n# such as the parser.out file.  If a user wants more detailed",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "MAXINT",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "MAXINT = sys.maxsize\n# This object is a stand-in for a logging object created by the\n# logging module.   PLY will use this by default to create things\n# such as the parser.out file.  If a user wants more detailed\n# information, they can create their own logging object and pass\n# it into PLY.\nclass PlyLogger(object):\n    def __init__(self, f):\n        self.f = f\n    def debug(self, msg, *args, **kwargs):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_errok",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_errok = None\n_token = None\n_restart = None\n_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_token",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_token = None\n_restart = None\n_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()\n'''",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_restart",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_restart = None\n_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()\n'''\ndef errok():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_warnmsg",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()\n'''\ndef errok():\n    warnings.warn(_warnmsg)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_is_identifier",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_is_identifier = re.compile(r'^[a-zA-Z0-9_-]+$')\n# -----------------------------------------------------------------------------\n# class Production:\n#\n# This class stores the raw information about a single production or grammar rule.\n# A grammar rule refers to a specification such as this:\n#\n#       expr : expr PLUS term\n#\n# Here are the basic attributes defined on all productions",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_tabversion",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_tabversion = %r\n_lr_method = %r\n_lr_signature = %r\n    ''' % (os.path.basename(filename), __tabversion__, self.lr_method, signature))\n            # Change smaller to 0 to go back to original tables\n            smaller = 1\n            # Factor out names to try and make smaller\n            if smaller:\n                items = {}\n                for s, nd in self.lr_action.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_method",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_method = %r\n_lr_signature = %r\n    ''' % (os.path.basename(filename), __tabversion__, self.lr_method, signature))\n            # Change smaller to 0 to go back to original tables\n            smaller = 1\n            # Factor out names to try and make smaller\n            if smaller:\n                items = {}\n                for s, nd in self.lr_action.items():\n                    for name, v in nd.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_signature",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_signature = %r\n    ''' % (os.path.basename(filename), __tabversion__, self.lr_method, signature))\n            # Change smaller to 0 to go back to original tables\n            smaller = 1\n            # Factor out names to try and make smaller\n            if smaller:\n                items = {}\n                for s, nd in self.lr_action.items():\n                    for name, v in nd.items():\n                        i = items.get(name)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_action",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n''')\n            else:\n                f.write('\\n_lr_action = { ')\n                for k, v in self.lr_action.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_goto",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):\n       if not _x in _lr_goto: _lr_goto[_x] = {}\n       _lr_goto[_x][_k] = _y\ndel _lr_goto_items\n''')\n            else:\n                f.write('\\n_lr_goto = { ')\n                for k, v in self.lr_goto.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "get_source_range",
        "kind": 2,
        "importPath": "ply.ygen",
        "description": "ply.ygen",
        "peekOfCode": "def get_source_range(lines, tag):\n    srclines = enumerate(lines)\n    start_tag = '#--! %s-start' % tag\n    end_tag = '#--! %s-end' % tag\n    for start_index, line in srclines:\n        if line.strip().startswith(start_tag):\n            break\n    for end_index, line in srclines:\n        if line.strip().endswith(end_tag):\n            break",
        "detail": "ply.ygen",
        "documentation": {}
    },
    {
        "label": "filter_section",
        "kind": 2,
        "importPath": "ply.ygen",
        "description": "ply.ygen",
        "peekOfCode": "def filter_section(lines, tag):\n    filtered_lines = []\n    include = True\n    tag_text = '#--! %s' % tag\n    for line in lines:\n        if line.strip().startswith(tag_text):\n            include = not include\n        elif include:\n            filtered_lines.append(line)\n    return filtered_lines",
        "detail": "ply.ygen",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ply.ygen",
        "description": "ply.ygen",
        "peekOfCode": "def main():\n    dirname = os.path.dirname(__file__)\n    shutil.copy2(os.path.join(dirname, 'yacc.py'), os.path.join(dirname, 'yacc.py.bak'))\n    with open(os.path.join(dirname, 'yacc.py'), 'r') as f:\n        lines = f.readlines()\n    parse_start, parse_end = get_source_range(lines, 'parsedebug')\n    parseopt_start, parseopt_end = get_source_range(lines, 'parseopt')\n    parseopt_notrack_start, parseopt_notrack_end = get_source_range(lines, 'parseopt-notrack')\n    # Get the original source\n    orig_lines = lines[parse_start:parse_end]",
        "detail": "ply.ygen",
        "documentation": {}
    },
    {
        "label": "_tabversion",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_tabversion = '3.10'\n_lr_method = 'LALR'\n_lr_signature = \"DEF DS ER GRM IG LEX LFUNC LTRG LTS PA PCA PCF PF PRA PRCD PREC PRF RT TKS TVAL TYPE YACC YFUNCS aspval cod id name nt pelval rgx symbolPly : Lexer YcLexer : LEX Literals Ignore Tokens Lfuncs LerrorYc : YACC Precedents Declarations Grammar YfsGrammar : GRM ProductionsYfs : YFUNCS FuncsLiterals : LTS '=' aspvalLiterals : Ignore : IG '=' aspvalIgnore : Tokens : TKS '=' PRA Tokl PRFTokl : Tokl ',' pelvalTokl : pelvalLfuncs : Lfuncs LfuncLfuncs : Lfunc : LFUNC rgx DS RT PA pelval ',' Tv PF Tv : TVALTv : TYPE PA TVAL PFLerror : ER Codes PFLerror : Precedents : PRCD '=' PRA Prcdlist PRFDeclarations : Declarations DeclarationDeclarations : Declaration : id '=' PProductions : Productions ProductionProductions : Production : nt DS Symbols PCA Codes PCFSymbols : Symbols SSymbols : S : symbolS : PREC symbolP : PRA PRFP : PCA PCFPrcdlist : Prcdlist PA LTRG ',' Pelvals pelval PF ','Prcdlist : Pelvals : Pelvals pelval ','Pelvals : Funcs : Funcs FuncFuncs : Func : DEF name PA name PF PCA Codes PCFCodes : Codes CodeCodes : Code : codCode : PA Codes PFCode : PRA Codes PRFCode : PCA Codes PCF\"\n_lr_action_items = {'LEX':([0,],[3,]),'$end':([1,4,27,28,37,49,100,],[0,-1,-3,-38,-5,-37,-39,]),'YACC':([2,15,24,32,33,55,62,98,],[5,-14,-19,-2,-13,-18,-10,-15,]),'LTS':([3,],[7,]),'IG':([3,6,18,],[-7,11,-6,]),'TKS':([3,6,10,18,26,],[-7,-9,16,-6,-8,]),'PRCD':([5,],[9,]),'=':([7,9,11,16,22,],[12,14,17,25,30,]),'GRM':([8,13,20,40,43,52,53,],[-22,21,-21,-23,-20,-31,-32,]),'id':([8,13,20,40,43,52,53,],[-22,22,-21,-23,-20,-31,-32,]),'aspval':([12,17,],[18,26,]),'PRA':([14,25,30,34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[23,36,41,-41,59,-40,-42,-41,-41,-41,59,59,59,-41,-43,-44,-45,59,-41,59,]),'ER':([15,24,33,62,98,],[-14,34,-13,-10,-15,]),'LFUNC':([15,24,33,62,98,],[-14,35,-13,-10,-15,]),'YFUNCS':([19,21,29,38,88,],[28,-25,-4,-24,-26,]),'nt':([21,29,38,88,],[-25,39,-24,-26,]),'PRF':([23,31,41,47,48,56,57,59,68,71,78,79,80,93,],[-34,43,52,62,-12,-40,-42,-41,79,-11,-43,-44,-45,-33,]),'PA':([23,31,34,45,56,57,58,59,60,64,67,68,69,70,73,78,79,80,83,92,93,96,97,],[-34,44,-41,58,-40,-42,-41,-41,-41,72,58,58,58,81,-41,-43,-44,-45,58,-41,-33,99,58,]),'DEF':([28,37,49,100,],[-38,50,-37,-39,]),'PCA':([30,34,45,51,56,57,58,59,60,65,67,68,69,73,74,75,78,79,80,83,84,87,92,97,],[42,-41,60,-28,-40,-42,-41,-41,-41,73,60,60,60,-41,-27,-29,-43,-44,-45,60,-30,92,-41,60,]),'PF':([34,45,56,57,58,67,78,79,80,82,85,94,95,101,102,],[-41,55,-40,-42,-41,78,-43,-44,-45,87,90,98,-16,102,-17,]),'cod':([34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[-41,57,-40,-42,-41,-41,-41,57,57,57,-41,-43,-44,-45,57,-41,57,]),'rgx':([35,],[46,]),'pelval':([36,63,66,77,81,89,],[48,71,-36,85,86,-35,]),'DS':([39,46,],[51,61,]),'PCF':([42,56,57,60,69,73,78,79,80,83,92,97,],[53,-40,-42,-41,80,-41,-43,-44,-45,88,-41,100,]),'LTRG':([44,],[54,]),',':([47,48,54,71,85,86,90,],[63,-12,66,-11,89,91,93,]),'name':([50,72,],[64,82,]),'symbol':([51,65,74,75,76,84,],[-28,75,-27,-29,84,-30,]),'PREC':([51,65,74,75,84,],[-28,76,-27,-29,-30,]),'RT':([61,],[70,]),'TVAL':([91,99,],[95,101,]),'TYPE':([91,],[96,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_method",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_lr_method = 'LALR'\n_lr_signature = \"DEF DS ER GRM IG LEX LFUNC LTRG LTS PA PCA PCF PF PRA PRCD PREC PRF RT TKS TVAL TYPE YACC YFUNCS aspval cod id name nt pelval rgx symbolPly : Lexer YcLexer : LEX Literals Ignore Tokens Lfuncs LerrorYc : YACC Precedents Declarations Grammar YfsGrammar : GRM ProductionsYfs : YFUNCS FuncsLiterals : LTS '=' aspvalLiterals : Ignore : IG '=' aspvalIgnore : Tokens : TKS '=' PRA Tokl PRFTokl : Tokl ',' pelvalTokl : pelvalLfuncs : Lfuncs LfuncLfuncs : Lfunc : LFUNC rgx DS RT PA pelval ',' Tv PF Tv : TVALTv : TYPE PA TVAL PFLerror : ER Codes PFLerror : Precedents : PRCD '=' PRA Prcdlist PRFDeclarations : Declarations DeclarationDeclarations : Declaration : id '=' PProductions : Productions ProductionProductions : Production : nt DS Symbols PCA Codes PCFSymbols : Symbols SSymbols : S : symbolS : PREC symbolP : PRA PRFP : PCA PCFPrcdlist : Prcdlist PA LTRG ',' Pelvals pelval PF ','Prcdlist : Pelvals : Pelvals pelval ','Pelvals : Funcs : Funcs FuncFuncs : Func : DEF name PA name PF PCA Codes PCFCodes : Codes CodeCodes : Code : codCode : PA Codes PFCode : PRA Codes PRFCode : PCA Codes PCF\"\n_lr_action_items = {'LEX':([0,],[3,]),'$end':([1,4,27,28,37,49,100,],[0,-1,-3,-38,-5,-37,-39,]),'YACC':([2,15,24,32,33,55,62,98,],[5,-14,-19,-2,-13,-18,-10,-15,]),'LTS':([3,],[7,]),'IG':([3,6,18,],[-7,11,-6,]),'TKS':([3,6,10,18,26,],[-7,-9,16,-6,-8,]),'PRCD':([5,],[9,]),'=':([7,9,11,16,22,],[12,14,17,25,30,]),'GRM':([8,13,20,40,43,52,53,],[-22,21,-21,-23,-20,-31,-32,]),'id':([8,13,20,40,43,52,53,],[-22,22,-21,-23,-20,-31,-32,]),'aspval':([12,17,],[18,26,]),'PRA':([14,25,30,34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[23,36,41,-41,59,-40,-42,-41,-41,-41,59,59,59,-41,-43,-44,-45,59,-41,59,]),'ER':([15,24,33,62,98,],[-14,34,-13,-10,-15,]),'LFUNC':([15,24,33,62,98,],[-14,35,-13,-10,-15,]),'YFUNCS':([19,21,29,38,88,],[28,-25,-4,-24,-26,]),'nt':([21,29,38,88,],[-25,39,-24,-26,]),'PRF':([23,31,41,47,48,56,57,59,68,71,78,79,80,93,],[-34,43,52,62,-12,-40,-42,-41,79,-11,-43,-44,-45,-33,]),'PA':([23,31,34,45,56,57,58,59,60,64,67,68,69,70,73,78,79,80,83,92,93,96,97,],[-34,44,-41,58,-40,-42,-41,-41,-41,72,58,58,58,81,-41,-43,-44,-45,58,-41,-33,99,58,]),'DEF':([28,37,49,100,],[-38,50,-37,-39,]),'PCA':([30,34,45,51,56,57,58,59,60,65,67,68,69,73,74,75,78,79,80,83,84,87,92,97,],[42,-41,60,-28,-40,-42,-41,-41,-41,73,60,60,60,-41,-27,-29,-43,-44,-45,60,-30,92,-41,60,]),'PF':([34,45,56,57,58,67,78,79,80,82,85,94,95,101,102,],[-41,55,-40,-42,-41,78,-43,-44,-45,87,90,98,-16,102,-17,]),'cod':([34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[-41,57,-40,-42,-41,-41,-41,57,57,57,-41,-43,-44,-45,57,-41,57,]),'rgx':([35,],[46,]),'pelval':([36,63,66,77,81,89,],[48,71,-36,85,86,-35,]),'DS':([39,46,],[51,61,]),'PCF':([42,56,57,60,69,73,78,79,80,83,92,97,],[53,-40,-42,-41,80,-41,-43,-44,-45,88,-41,100,]),'LTRG':([44,],[54,]),',':([47,48,54,71,85,86,90,],[63,-12,66,-11,89,91,93,]),'name':([50,72,],[64,82,]),'symbol':([51,65,74,75,76,84,],[-28,75,-27,-29,84,-30,]),'PREC':([51,65,74,75,84,],[-28,76,-27,-29,-30,]),'RT':([61,],[70,]),'TVAL':([91,99,],[95,101,]),'TYPE':([91,],[96,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'Ply':([0,],[1,]),'Lexer':([0,],[2,]),'Yc':([2,],[4,]),'Literals':([3,],[6,]),'Precedents':([5,],[8,]),'Ignore':([6,],[10,]),'Declarations':([8,],[13,]),'Tokens':([10,],[15,]),'Grammar':([13,],[19,]),'Declaration':([13,],[20,]),'Lfuncs':([15,],[24,]),'Yfs':([19,],[27,]),'Productions':([21,],[29,]),'Prcdlist':([23,],[31,]),'Lerror':([24,],[32,]),'Lfunc':([24,],[33,]),'Funcs':([28,],[37,]),'Production':([29,],[38,]),'P':([30,],[40,]),'Codes':([34,58,59,60,73,92,],[45,67,68,69,83,97,]),'Tokl':([36,],[47,]),'Func':([37,],[49,]),'Code':([45,67,68,69,83,97,],[56,56,56,56,56,56,]),'Symbols':([51,],[65,]),'S':([65,],[74,]),'Pelvals':([66,],[77,]),'Tv':([91,],[94,]),}",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_signature",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_lr_signature = \"DEF DS ER GRM IG LEX LFUNC LTRG LTS PA PCA PCF PF PRA PRCD PREC PRF RT TKS TVAL TYPE YACC YFUNCS aspval cod id name nt pelval rgx symbolPly : Lexer YcLexer : LEX Literals Ignore Tokens Lfuncs LerrorYc : YACC Precedents Declarations Grammar YfsGrammar : GRM ProductionsYfs : YFUNCS FuncsLiterals : LTS '=' aspvalLiterals : Ignore : IG '=' aspvalIgnore : Tokens : TKS '=' PRA Tokl PRFTokl : Tokl ',' pelvalTokl : pelvalLfuncs : Lfuncs LfuncLfuncs : Lfunc : LFUNC rgx DS RT PA pelval ',' Tv PF Tv : TVALTv : TYPE PA TVAL PFLerror : ER Codes PFLerror : Precedents : PRCD '=' PRA Prcdlist PRFDeclarations : Declarations DeclarationDeclarations : Declaration : id '=' PProductions : Productions ProductionProductions : Production : nt DS Symbols PCA Codes PCFSymbols : Symbols SSymbols : S : symbolS : PREC symbolP : PRA PRFP : PCA PCFPrcdlist : Prcdlist PA LTRG ',' Pelvals pelval PF ','Prcdlist : Pelvals : Pelvals pelval ','Pelvals : Funcs : Funcs FuncFuncs : Func : DEF name PA name PF PCA Codes PCFCodes : Codes CodeCodes : Code : codCode : PA Codes PFCode : PRA Codes PRFCode : PCA Codes PCF\"\n_lr_action_items = {'LEX':([0,],[3,]),'$end':([1,4,27,28,37,49,100,],[0,-1,-3,-38,-5,-37,-39,]),'YACC':([2,15,24,32,33,55,62,98,],[5,-14,-19,-2,-13,-18,-10,-15,]),'LTS':([3,],[7,]),'IG':([3,6,18,],[-7,11,-6,]),'TKS':([3,6,10,18,26,],[-7,-9,16,-6,-8,]),'PRCD':([5,],[9,]),'=':([7,9,11,16,22,],[12,14,17,25,30,]),'GRM':([8,13,20,40,43,52,53,],[-22,21,-21,-23,-20,-31,-32,]),'id':([8,13,20,40,43,52,53,],[-22,22,-21,-23,-20,-31,-32,]),'aspval':([12,17,],[18,26,]),'PRA':([14,25,30,34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[23,36,41,-41,59,-40,-42,-41,-41,-41,59,59,59,-41,-43,-44,-45,59,-41,59,]),'ER':([15,24,33,62,98,],[-14,34,-13,-10,-15,]),'LFUNC':([15,24,33,62,98,],[-14,35,-13,-10,-15,]),'YFUNCS':([19,21,29,38,88,],[28,-25,-4,-24,-26,]),'nt':([21,29,38,88,],[-25,39,-24,-26,]),'PRF':([23,31,41,47,48,56,57,59,68,71,78,79,80,93,],[-34,43,52,62,-12,-40,-42,-41,79,-11,-43,-44,-45,-33,]),'PA':([23,31,34,45,56,57,58,59,60,64,67,68,69,70,73,78,79,80,83,92,93,96,97,],[-34,44,-41,58,-40,-42,-41,-41,-41,72,58,58,58,81,-41,-43,-44,-45,58,-41,-33,99,58,]),'DEF':([28,37,49,100,],[-38,50,-37,-39,]),'PCA':([30,34,45,51,56,57,58,59,60,65,67,68,69,73,74,75,78,79,80,83,84,87,92,97,],[42,-41,60,-28,-40,-42,-41,-41,-41,73,60,60,60,-41,-27,-29,-43,-44,-45,60,-30,92,-41,60,]),'PF':([34,45,56,57,58,67,78,79,80,82,85,94,95,101,102,],[-41,55,-40,-42,-41,78,-43,-44,-45,87,90,98,-16,102,-17,]),'cod':([34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[-41,57,-40,-42,-41,-41,-41,57,57,57,-41,-43,-44,-45,57,-41,57,]),'rgx':([35,],[46,]),'pelval':([36,63,66,77,81,89,],[48,71,-36,85,86,-35,]),'DS':([39,46,],[51,61,]),'PCF':([42,56,57,60,69,73,78,79,80,83,92,97,],[53,-40,-42,-41,80,-41,-43,-44,-45,88,-41,100,]),'LTRG':([44,],[54,]),',':([47,48,54,71,85,86,90,],[63,-12,66,-11,89,91,93,]),'name':([50,72,],[64,82,]),'symbol':([51,65,74,75,76,84,],[-28,75,-27,-29,84,-30,]),'PREC':([51,65,74,75,84,],[-28,76,-27,-29,-30,]),'RT':([61,],[70,]),'TVAL':([91,99,],[95,101,]),'TYPE':([91,],[96,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'Ply':([0,],[1,]),'Lexer':([0,],[2,]),'Yc':([2,],[4,]),'Literals':([3,],[6,]),'Precedents':([5,],[8,]),'Ignore':([6,],[10,]),'Declarations':([8,],[13,]),'Tokens':([10,],[15,]),'Grammar':([13,],[19,]),'Declaration':([13,],[20,]),'Lfuncs':([15,],[24,]),'Yfs':([19,],[27,]),'Productions':([21,],[29,]),'Prcdlist':([23,],[31,]),'Lerror':([24,],[32,]),'Lfunc':([24,],[33,]),'Funcs':([28,],[37,]),'Production':([29,],[38,]),'P':([30,],[40,]),'Codes':([34,58,59,60,73,92,],[45,67,68,69,83,97,]),'Tokl':([36,],[47,]),'Func':([37,],[49,]),'Code':([45,67,68,69,83,97,],[56,56,56,56,56,56,]),'Symbols':([51,],[65,]),'S':([65,],[74,]),'Pelvals':([66,],[77,]),'Tv':([91,],[94,]),}\n_lr_goto = {}",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_action_items",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_lr_action_items = {'LEX':([0,],[3,]),'$end':([1,4,27,28,37,49,100,],[0,-1,-3,-38,-5,-37,-39,]),'YACC':([2,15,24,32,33,55,62,98,],[5,-14,-19,-2,-13,-18,-10,-15,]),'LTS':([3,],[7,]),'IG':([3,6,18,],[-7,11,-6,]),'TKS':([3,6,10,18,26,],[-7,-9,16,-6,-8,]),'PRCD':([5,],[9,]),'=':([7,9,11,16,22,],[12,14,17,25,30,]),'GRM':([8,13,20,40,43,52,53,],[-22,21,-21,-23,-20,-31,-32,]),'id':([8,13,20,40,43,52,53,],[-22,22,-21,-23,-20,-31,-32,]),'aspval':([12,17,],[18,26,]),'PRA':([14,25,30,34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[23,36,41,-41,59,-40,-42,-41,-41,-41,59,59,59,-41,-43,-44,-45,59,-41,59,]),'ER':([15,24,33,62,98,],[-14,34,-13,-10,-15,]),'LFUNC':([15,24,33,62,98,],[-14,35,-13,-10,-15,]),'YFUNCS':([19,21,29,38,88,],[28,-25,-4,-24,-26,]),'nt':([21,29,38,88,],[-25,39,-24,-26,]),'PRF':([23,31,41,47,48,56,57,59,68,71,78,79,80,93,],[-34,43,52,62,-12,-40,-42,-41,79,-11,-43,-44,-45,-33,]),'PA':([23,31,34,45,56,57,58,59,60,64,67,68,69,70,73,78,79,80,83,92,93,96,97,],[-34,44,-41,58,-40,-42,-41,-41,-41,72,58,58,58,81,-41,-43,-44,-45,58,-41,-33,99,58,]),'DEF':([28,37,49,100,],[-38,50,-37,-39,]),'PCA':([30,34,45,51,56,57,58,59,60,65,67,68,69,73,74,75,78,79,80,83,84,87,92,97,],[42,-41,60,-28,-40,-42,-41,-41,-41,73,60,60,60,-41,-27,-29,-43,-44,-45,60,-30,92,-41,60,]),'PF':([34,45,56,57,58,67,78,79,80,82,85,94,95,101,102,],[-41,55,-40,-42,-41,78,-43,-44,-45,87,90,98,-16,102,-17,]),'cod':([34,45,56,57,58,59,60,67,68,69,73,78,79,80,83,92,97,],[-41,57,-40,-42,-41,-41,-41,57,57,57,-41,-43,-44,-45,57,-41,57,]),'rgx':([35,],[46,]),'pelval':([36,63,66,77,81,89,],[48,71,-36,85,86,-35,]),'DS':([39,46,],[51,61,]),'PCF':([42,56,57,60,69,73,78,79,80,83,92,97,],[53,-40,-42,-41,80,-41,-43,-44,-45,88,-41,100,]),'LTRG':([44,],[54,]),',':([47,48,54,71,85,86,90,],[63,-12,66,-11,89,91,93,]),'name':([50,72,],[64,82,]),'symbol':([51,65,74,75,76,84,],[-28,75,-27,-29,84,-30,]),'PREC':([51,65,74,75,84,],[-28,76,-27,-29,-30,]),'RT':([61,],[70,]),'TVAL':([91,99,],[95,101,]),'TYPE':([91,],[96,]),}\n_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'Ply':([0,],[1,]),'Lexer':([0,],[2,]),'Yc':([2,],[4,]),'Literals':([3,],[6,]),'Precedents':([5,],[8,]),'Ignore':([6,],[10,]),'Declarations':([8,],[13,]),'Tokens':([10,],[15,]),'Grammar':([13,],[19,]),'Declaration':([13,],[20,]),'Lfuncs':([15,],[24,]),'Yfs':([19,],[27,]),'Productions':([21,],[29,]),'Prcdlist':([23,],[31,]),'Lerror':([24,],[32,]),'Lfunc':([24,],[33,]),'Funcs':([28,],[37,]),'Production':([29,],[38,]),'P':([30,],[40,]),'Codes':([34,58,59,60,73,92,],[45,67,68,69,83,97,]),'Tokl':([36,],[47,]),'Func':([37,],[49,]),'Code':([45,67,68,69,83,97,],[56,56,56,56,56,56,]),'Symbols':([51,],[65,]),'S':([65,],[74,]),'Pelvals':([66,],[77,]),'Tv':([91,],[94,]),}\n_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_action",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n_lr_goto_items = {'Ply':([0,],[1,]),'Lexer':([0,],[2,]),'Yc':([2,],[4,]),'Literals':([3,],[6,]),'Precedents':([5,],[8,]),'Ignore':([6,],[10,]),'Declarations':([8,],[13,]),'Tokens':([10,],[15,]),'Grammar':([13,],[19,]),'Declaration':([13,],[20,]),'Lfuncs':([15,],[24,]),'Yfs':([19,],[27,]),'Productions':([21,],[29,]),'Prcdlist':([23,],[31,]),'Lerror':([24,],[32,]),'Lfunc':([24,],[33,]),'Funcs':([28,],[37,]),'Production':([29,],[38,]),'P':([30,],[40,]),'Codes':([34,58,59,60,73,92,],[45,67,68,69,83,97,]),'Tokl':([36,],[47,]),'Func':([37,],[49,]),'Code':([45,67,68,69,83,97,],[56,56,56,56,56,56,]),'Symbols':([51,],[65,]),'S':([65,],[74,]),'Pelvals':([66,],[77,]),'Tv':([91,],[94,]),}\n_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_goto_items",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_lr_goto_items = {'Ply':([0,],[1,]),'Lexer':([0,],[2,]),'Yc':([2,],[4,]),'Literals':([3,],[6,]),'Precedents':([5,],[8,]),'Ignore':([6,],[10,]),'Declarations':([8,],[13,]),'Tokens':([10,],[15,]),'Grammar':([13,],[19,]),'Declaration':([13,],[20,]),'Lfuncs':([15,],[24,]),'Yfs':([19,],[27,]),'Productions':([21,],[29,]),'Prcdlist':([23,],[31,]),'Lerror':([24,],[32,]),'Lfunc':([24,],[33,]),'Funcs':([28,],[37,]),'Production':([29,],[38,]),'P':([30,],[40,]),'Codes':([34,58,59,60,73,92,],[45,67,68,69,83,97,]),'Tokl':([36,],[47,]),'Func':([37,],[49,]),'Code':([45,67,68,69,83,97,],[56,56,56,56,56,56,]),'Symbols':([51,],[65,]),'S':([65,],[74,]),'Pelvals':([66,],[77,]),'Tv':([91,],[94,]),}\n_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):\n       if not _x in _lr_goto: _lr_goto[_x] = {}\n       _lr_goto[_x][_k] = _y\ndel _lr_goto_items\n_lr_productions = [\n  (\"S' -> Ply\",\"S'\",1,None,None,None),\n  ('Ply -> Lexer Yc','Ply',2,'p_Ply','plysimple_sin.py',6),",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_goto",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):\n       if not _x in _lr_goto: _lr_goto[_x] = {}\n       _lr_goto[_x][_k] = _y\ndel _lr_goto_items\n_lr_productions = [\n  (\"S' -> Ply\",\"S'\",1,None,None,None),\n  ('Ply -> Lexer Yc','Ply',2,'p_Ply','plysimple_sin.py',6),\n  ('Lexer -> LEX Literals Ignore Tokens Lfuncs Lerror','Lexer',6,'p_Lexer','plysimple_sin.py',10),",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "_lr_productions",
        "kind": 5,
        "importPath": "parsetab",
        "description": "parsetab",
        "peekOfCode": "_lr_productions = [\n  (\"S' -> Ply\",\"S'\",1,None,None,None),\n  ('Ply -> Lexer Yc','Ply',2,'p_Ply','plysimple_sin.py',6),\n  ('Lexer -> LEX Literals Ignore Tokens Lfuncs Lerror','Lexer',6,'p_Lexer','plysimple_sin.py',10),\n  ('Yc -> YACC Precedents Declarations Grammar Yfs','Yc',5,'p_Yc','plysimple_sin.py',14),\n  ('Grammar -> GRM Productions','Grammar',2,'p_Grammar','plysimple_sin.py',18),\n  ('Yfs -> YFUNCS Funcs','Yfs',2,'p_Yfs','plysimple_sin.py',22),\n  ('Literals -> LTS = aspval','Literals',3,'p_Literals','plysimple_sin.py',26),\n  ('Literals -> <empty>','Literals',0,'p_Literals_empty','plysimple_sin.py',32),\n  ('Ignore -> IG = aspval','Ignore',3,'p_Ignore','plysimple_sin.py',36),",
        "detail": "parsetab",
        "documentation": {}
    },
    {
        "label": "t_LX",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_LX(t):\n    r\"LEX:\"\n    return t\ndef t_LT(t):\n    r\"literals\"\n    return t\ndef t_IG(t):\n    r\"ignore\"\n    return t\ndef t_TK(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_LT",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_LT(t):\n    r\"literals\"\n    return t\ndef t_IG(t):\n    r\"ignore\"\n    return t\ndef t_TK(t):\n    r\"tokens\"\n    return t\ndef t_RT(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_IG",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_IG(t):\n    r\"ignore\"\n    return t\ndef t_TK(t):\n    r\"tokens\"\n    return t\ndef t_RT(t):\n    r\"return\"\n    return t\ndef t_TVALUE(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_TK",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_TK(t):\n    r\"tokens\"\n    return t\ndef t_RT(t):\n    r\"return\"\n    return t\ndef t_TVALUE(t):\n    r\"t.value\"\n    return t\ndef t_DEC(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_RT",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_RT(t):\n    r\"return\"\n    return t\ndef t_TVALUE(t):\n    r\"t.value\"\n    return t\ndef t_DEC(t):\n    r\"declatarion:\"\n    return t\ndef t_PRECEDENT(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_TVALUE",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_TVALUE(t):\n    r\"t.value\"\n    return t\ndef t_DEC(t):\n    r\"declatarion:\"\n    return t\ndef t_PRECEDENT(t):\n    r\"precedend\"\n    return t\ndef t_GRAMMAR_PREC(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_DEC",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_DEC(t):\n    r\"declatarion:\"\n    return t\ndef t_PRECEDENT(t):\n    r\"precedend\"\n    return t\ndef t_GRAMMAR_PREC(t):\n    r\"%prec\"\n    return t\ndef t_LEFT(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_PRECEDENT",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_PRECEDENT(t):\n    r\"precedend\"\n    return t\ndef t_GRAMMAR_PREC(t):\n    r\"%prec\"\n    return t\ndef t_LEFT(t):\n    r\"'left'\"\n    return t\ndef t_RIGHT(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_PREC",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_GRAMMAR_PREC(t):\n    r\"%prec\"\n    return t\ndef t_LEFT(t):\n    r\"'left'\"\n    return t\ndef t_RIGHT(t):\n    r\"'right'\"\n    return t\ndef t_grammar(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_LEFT",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_LEFT(t):\n    r\"'left'\"\n    return t\ndef t_RIGHT(t):\n    r\"'right'\"\n    return t\ndef t_grammar(t):\n    r\"grammar:\"\n    t.lexer.push_state('GRAMMAR')\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_RIGHT",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_RIGHT(t):\n    r\"'right'\"\n    return t\ndef t_grammar(t):\n    r\"grammar:\"\n    t.lexer.push_state('GRAMMAR')\n    return t\ndef t_INITIAL_DEF(t):\n    r\"def\"\n    t.lexer.push_state('YFUNC')",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_grammar",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_grammar(t):\n    r\"grammar:\"\n    t.lexer.push_state('GRAMMAR')\n    return t\ndef t_INITIAL_DEF(t):\n    r\"def\"\n    t.lexer.push_state('YFUNC')\n    return t\ndef t_YFUNC_DEF(t):\n    r\"def\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_DEF",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_INITIAL_DEF(t):\n    r\"def\"\n    t.lexer.push_state('YFUNC')\n    return t\ndef t_YFUNC_DEF(t):\n    r\"def\"\n    return t\ndef t_YFUNC_FUNC(t):\n    r\"[a-z][\\w_]*\"\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_YFUNC_DEF",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_YFUNC_DEF(t):\n    r\"def\"\n    return t\ndef t_YFUNC_FUNC(t):\n    r\"[a-z][\\w_]*\"\n    return t\ndef t_ARGS_arg(t):\n    r\"[a-z]+\"\n    return t\ndef t_ER(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_YFUNC_FUNC",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_YFUNC_FUNC(t):\n    r\"[a-z][\\w_]*\"\n    return t\ndef t_ARGS_arg(t):\n    r\"[a-z]+\"\n    return t\ndef t_ER(t):\n    r\"error\\(\"\n    t.lexer.push_state('CODIGO')\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_ARGS_arg",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_ARGS_arg(t):\n    r\"[a-z]+\"\n    return t\ndef t_ER(t):\n    r\"error\\(\"\n    t.lexer.push_state('CODIGO')\n    return t\ndef t_TYPE(t):\n    r\"(float)|(int)|(double)\"\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_ER",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_ER(t):\n    r\"error\\(\"\n    t.lexer.push_state('CODIGO')\n    return t\ndef t_TYPE(t):\n    r\"(float)|(int)|(double)\"\n    return t\ndef t_LFUNC(t):\n    r\"lfunc:\"\n    t.lexer.push_state('REGEX')",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_TYPE",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_TYPE(t):\n    r\"(float)|(int)|(double)\"\n    return t\ndef t_LFUNC(t):\n    r\"lfunc:\"\n    t.lexer.push_state('REGEX')\n    return t\ndef t_REGEX_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_LFUNC",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_LFUNC(t):\n    r\"lfunc:\"\n    t.lexer.push_state('REGEX')\n    return t\ndef t_REGEX_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()\n    return t\ndef t_GRAMMAR_YFUNC_CODIGO_PCA(t):\n    r\"{\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_REGEX_PCA",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_REGEX_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()\n    return t\ndef t_GRAMMAR_YFUNC_CODIGO_PCA(t):\n    r\"{\"\n    t.lexer.push_state('CODIGO')\n    return t\ndef t_CODIGO_PCF(t):\n    r\"}\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_YFUNC_CODIGO_PCA",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_GRAMMAR_YFUNC_CODIGO_PCA(t):\n    r\"{\"\n    t.lexer.push_state('CODIGO')\n    return t\ndef t_CODIGO_PCF(t):\n    r\"}\"\n    t.lexer.pop_state()\n    return t\ndef t_PCA(t):\n    r\"{\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_CODIGO_PCF",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_CODIGO_PCF(t):\n    r\"}\"\n    t.lexer.pop_state()\n    return t\ndef t_PCA(t):\n    r\"{\"\n    return t\ndef t_PCF(t):\n    r\"}\"\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_PCA",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_PCA(t):\n    r\"{\"\n    return t\ndef t_PCF(t):\n    r\"}\"\n    return t\ndef t_INITIAL_PA(t):\n    r\"\\(\"\n    return t\ndef t_YFUNC_PA(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_PCF",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_PCF(t):\n    r\"}\"\n    return t\ndef t_INITIAL_PA(t):\n    r\"\\(\"\n    return t\ndef t_YFUNC_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('ARGS')\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_PA",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_INITIAL_PA(t):\n    r\"\\(\"\n    return t\ndef t_YFUNC_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('ARGS')\n    return t\ndef t_INITIAL_CODIGO_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('CODIGO')",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_YFUNC_PA",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_YFUNC_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('ARGS')\n    return t\ndef t_INITIAL_CODIGO_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('CODIGO')\n    return t\ndef t_ARGS_CODIGO_PF(t):\n    r\"\\)\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_CODIGO_PA",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_INITIAL_CODIGO_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('CODIGO')\n    return t\ndef t_ARGS_CODIGO_PF(t):\n    r\"\\)\"\n    t.lexer.pop_state()\n    return t\ndef t_INITIAL_YFUNC_PF(t):\n    r\"\\)\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_ARGS_CODIGO_PF",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_ARGS_CODIGO_PF(t):\n    r\"\\)\"\n    t.lexer.pop_state()\n    return t\ndef t_INITIAL_YFUNC_PF(t):\n    r\"\\)\"\n    return t\ndef t_YC(t):\n    r\"YACC:\"\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_YFUNC_PF",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_INITIAL_YFUNC_PF(t):\n    r\"\\)\"\n    return t\ndef t_YC(t):\n    r\"YACC:\"\n    return t\ndef t_GRAMMAR_yfuncs(t):\n    r\"yfuncs:\"\n    t.lexer.pop_state()\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_YC",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_YC(t):\n    r\"YACC:\"\n    return t\ndef t_GRAMMAR_yfuncs(t):\n    r\"yfuncs:\"\n    t.lexer.pop_state()\n    return t\ndef t_REGEX_DOTS(t):\n    r\":\"\n    t.lexer.pop_state()",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_yfuncs",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_GRAMMAR_yfuncs(t):\n    r\"yfuncs:\"\n    t.lexer.pop_state()\n    return t\ndef t_REGEX_DOTS(t):\n    r\":\"\n    t.lexer.pop_state()\n    return t\ndef t_INITIAL_GRAMMAR_DOTS(t):\n    r\":\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_REGEX_DOTS",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_REGEX_DOTS(t):\n    r\":\"\n    t.lexer.pop_state()\n    return t\ndef t_INITIAL_GRAMMAR_DOTS(t):\n    r\":\"\n    return t\ndef t_YFUNCS_DOTS(t):\n    r\":\\n\"\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_GRAMMAR_DOTS",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_INITIAL_GRAMMAR_DOTS(t):\n    r\":\"\n    return t\ndef t_YFUNCS_DOTS(t):\n    r\":\\n\"\n    return t\ndef t_REGEX_RGX(t):\n    r\"((\\\\:)|[^:])+\"\n    return t\ndef t_aspval(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_YFUNCS_DOTS",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_YFUNCS_DOTS(t):\n    r\":\\n\"\n    return t\ndef t_REGEX_RGX(t):\n    r\"((\\\\:)|[^:])+\"\n    return t\ndef t_aspval(t):\n    r\"\\\"[^0-9\\n]+\\\"\" #n percebo porque é que se puser \\n funciona..\n    return t\ndef t_pelval(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_REGEX_RGX",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_REGEX_RGX(t):\n    r\"((\\\\:)|[^:])+\"\n    return t\ndef t_aspval(t):\n    r\"\\\"[^0-9\\n]+\\\"\" #n percebo porque é que se puser \\n funciona..\n    return t\ndef t_pelval(t):\n    r\"'[^']+'\"\n    return t\ndef t_GRAMMAR_NT(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_aspval",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_aspval(t):\n    r\"\\\"[^0-9\\n]+\\\"\" #n percebo porque é que se puser \\n funciona..\n    return t\ndef t_pelval(t):\n    r\"'[^']+'\"\n    return t\ndef t_GRAMMAR_NT(t):\n    r\"[a-z]+\"\n    return t\ndef t_GRAMMAR_T(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_pelval",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_pelval(t):\n    r\"'[^']+'\"\n    return t\ndef t_GRAMMAR_NT(t):\n    r\"[a-z]+\"\n    return t\ndef t_GRAMMAR_T(t):\n    r\"[A-Z]+\"\n    return t\ndef t_GRAMMAR_L(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_NT",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_GRAMMAR_NT(t):\n    r\"[a-z]+\"\n    return t\ndef t_GRAMMAR_T(t):\n    r\"[A-Z]+\"\n    return t\ndef t_GRAMMAR_L(t):\n    r\"'.'\"\n    return t\ndef t_ID(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_T",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_GRAMMAR_T(t):\n    r\"[A-Z]+\"\n    return t\ndef t_GRAMMAR_L(t):\n    r\"'.'\"\n    return t\ndef t_ID(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_CODIGO_cod(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_L",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_GRAMMAR_L(t):\n    r\"'.'\"\n    return t\ndef t_ID(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_CODIGO_cod(t):\n    r\"([^{}\\(\\)])+\"\n    return t\ndef t_YFUNC_cod(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_ID",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_ID(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_CODIGO_cod(t):\n    r\"([^{}\\(\\)])+\"\n    return t\ndef t_YFUNC_cod(t):\n    r\"\\t[^\\n]+\\n\"\n    return t\ndef t_ANY_error(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_CODIGO_cod",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_CODIGO_cod(t):\n    r\"([^{}\\(\\)])+\"\n    return t\ndef t_YFUNC_cod(t):\n    r\"\\t[^\\n]+\\n\"\n    return t\ndef t_ANY_error(t):\n    print(f\"Illegal character '{t.value[0]}', [{t.lexer.lineno}]\")\n    t.lexer.skip(1)\nlexer = lex.lex()",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_YFUNC_cod",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_YFUNC_cod(t):\n    r\"\\t[^\\n]+\\n\"\n    return t\ndef t_ANY_error(t):\n    print(f\"Illegal character '{t.value[0]}', [{t.lexer.lineno}]\")\n    t.lexer.skip(1)\nlexer = lex.lex()\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())\nfor token in lexer:",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_ANY_error",
        "kind": 2,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "def t_ANY_error(t):\n    print(f\"Illegal character '{t.value[0]}', [{t.lexer.lineno}]\")\n    t.lexer.skip(1)\nlexer = lex.lex()\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())\nfor token in lexer:\n    print(token)",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "states",
        "kind": 5,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "states = [('REGEX','exclusive'),('GRAMMAR','exclusive'),('CODIGO','exclusive'),('YFUNC','exclusive'),('ARGS','exclusive')]\nliterals = ['=',',','[',']']\ntokens = [\"LX\",\"LT\",\"IG\",\"TK\",\"RGX\",\"YC\",\"DOTS\",\"RT\",\"TVALUE\",\"PA\",\"PF\",\"PCA\",\"PCF\",\"TYPE\",\"aspval\",\"pelval\",\"str\",\"DEC\"\n,\"PRECEDENT\",\"PREC\",\"LEFT\",\"RIGHT\",\"ID\",\"NT\",\"T\",\"grammar\",\"yfuncs\",\"L\",\"ER\",\"cod\",\"LFUNC\",\"DEF\",\"FUNC\",\"arg\"]\nt_ANY_ignore = \"\\t\\n \"\ndef t_LX(t):\n    r\"LEX:\"\n    return t\ndef t_LT(t):\n    r\"literals\"",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "literals",
        "kind": 5,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "literals = ['=',',','[',']']\ntokens = [\"LX\",\"LT\",\"IG\",\"TK\",\"RGX\",\"YC\",\"DOTS\",\"RT\",\"TVALUE\",\"PA\",\"PF\",\"PCA\",\"PCF\",\"TYPE\",\"aspval\",\"pelval\",\"str\",\"DEC\"\n,\"PRECEDENT\",\"PREC\",\"LEFT\",\"RIGHT\",\"ID\",\"NT\",\"T\",\"grammar\",\"yfuncs\",\"L\",\"ER\",\"cod\",\"LFUNC\",\"DEF\",\"FUNC\",\"arg\"]\nt_ANY_ignore = \"\\t\\n \"\ndef t_LX(t):\n    r\"LEX:\"\n    return t\ndef t_LT(t):\n    r\"literals\"\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "tokens = [\"LX\",\"LT\",\"IG\",\"TK\",\"RGX\",\"YC\",\"DOTS\",\"RT\",\"TVALUE\",\"PA\",\"PF\",\"PCA\",\"PCF\",\"TYPE\",\"aspval\",\"pelval\",\"str\",\"DEC\"\n,\"PRECEDENT\",\"PREC\",\"LEFT\",\"RIGHT\",\"ID\",\"NT\",\"T\",\"grammar\",\"yfuncs\",\"L\",\"ER\",\"cod\",\"LFUNC\",\"DEF\",\"FUNC\",\"arg\"]\nt_ANY_ignore = \"\\t\\n \"\ndef t_LX(t):\n    r\"LEX:\"\n    return t\ndef t_LT(t):\n    r\"literals\"\n    return t\ndef t_IG(t):",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_ANY_ignore",
        "kind": 5,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "t_ANY_ignore = \"\\t\\n \"\ndef t_LX(t):\n    r\"LEX:\"\n    return t\ndef t_LT(t):\n    r\"literals\"\n    return t\ndef t_IG(t):\n    r\"ignore\"\n    return t",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "lexer",
        "kind": 5,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "lexer = lex.lex()\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())\nfor token in lexer:\n    print(token)",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "file",
        "kind": 5,
        "importPath": "plysimple_lex",
        "description": "plysimple_lex",
        "peekOfCode": "file = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())\nfor token in lexer:\n    print(token)",
        "detail": "plysimple_lex",
        "documentation": {}
    },
    {
        "label": "t_LEX",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_LEX(t):\n    r'LEX:'\n    return t\ndef t_LTS(t):\n    r\"literals\"\n    return t\ndef t_IG(t):\n    r\"ignore\"\n    return t\ndef t_TKS(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_LTS",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_LTS(t):\n    r\"literals\"\n    return t\ndef t_IG(t):\n    r\"ignore\"\n    return t\ndef t_TKS(t):\n    r\"tokens\"\n    return t\ndef t_LFUNC(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_IG",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_IG(t):\n    r\"ignore\"\n    return t\ndef t_TKS(t):\n    r\"tokens\"\n    return t\ndef t_LFUNC(t):\n    r\"lfunc:\"\n    t.lexer.push_state('REGEX')\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_TKS",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_TKS(t):\n    r\"tokens\"\n    return t\ndef t_LFUNC(t):\n    r\"lfunc:\"\n    t.lexer.push_state('REGEX')\n    return t\ndef t_RT(t):\n    r\"return\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_LFUNC",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_LFUNC(t):\n    r\"lfunc:\"\n    t.lexer.push_state('REGEX')\n    return t\ndef t_RT(t):\n    r\"return\"\n    return t\ndef t_ER(t):\n    r\"lerror\\(\"\n    t.lexer.push_state('CODE')",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_RT",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_RT(t):\n    r\"return\"\n    return t\ndef t_ER(t):\n    r\"lerror\\(\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_TVAL(t):\n    r\"t.value\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_ER",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_ER(t):\n    r\"lerror\\(\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_TVAL(t):\n    r\"t.value\"\n    return t\ndef t_TYPE(t):\n    r\"(float)|(int)|(double)\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_TVAL",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_TVAL(t):\n    r\"t.value\"\n    return t\ndef t_TYPE(t):\n    r\"(float)|(int)|(double)\"\n    return t\ndef t_YACC(t):\n    r\"YACC:\"\n    return t\ndef t_PRCD(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_TYPE",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_TYPE(t):\n    r\"(float)|(int)|(double)\"\n    return t\ndef t_YACC(t):\n    r\"YACC:\"\n    return t\ndef t_PRCD(t):\n    r\"precedend\"\n    return t\ndef t_LTRG(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_YACC",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_YACC(t):\n    r\"YACC:\"\n    return t\ndef t_PRCD(t):\n    r\"precedend\"\n    return t\ndef t_LTRG(t):\n    r\"('left')|('right')\"\n    return t\ndef t_GRM(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_PRCD",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_PRCD(t):\n    r\"precedend\"\n    return t\ndef t_LTRG(t):\n    r\"('left')|('right')\"\n    return t\ndef t_GRM(t):\n    r\"grammar:\"\n    t.lexer.push_state('GRAMMAR')\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_LTRG",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_LTRG(t):\n    r\"('left')|('right')\"\n    return t\ndef t_GRM(t):\n    r\"grammar:\"\n    t.lexer.push_state('GRAMMAR')\n    return t\ndef t_SYMBOLS_PREC(t):\n    r\"%prec\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_GRM",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_GRM(t):\n    r\"grammar:\"\n    t.lexer.push_state('GRAMMAR')\n    return t\ndef t_SYMBOLS_PREC(t):\n    r\"%prec\"\n    return t\ndef t_GRAMMAR_YFUNCS(t):\n    r\"yfuncs:\"\n    t.lexer.pop_state()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_SYMBOLS_PREC",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_SYMBOLS_PREC(t):\n    r\"%prec\"\n    return t\ndef t_GRAMMAR_YFUNCS(t):\n    r\"yfuncs:\"\n    t.lexer.pop_state()\n    return t\ndef t_DEF(t):\n    r\"def\"\n    t.lexer.push_state('YFUNC')",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_YFUNCS",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_GRAMMAR_YFUNCS(t):\n    r\"yfuncs:\"\n    t.lexer.pop_state()\n    return t\ndef t_DEF(t):\n    r\"def\"\n    t.lexer.push_state('YFUNC')\n    return t\ndef t_YFUNC_DEF(t):\n    r\"def\"",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_DEF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_DEF(t):\n    r\"def\"\n    t.lexer.push_state('YFUNC')\n    return t\ndef t_YFUNC_DEF(t):\n    r\"def\"\n    return t\ndef t_INITIAL_YFUNC_PA(t):\n    r\"\\(\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_YFUNC_DEF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_YFUNC_DEF(t):\n    r\"def\"\n    return t\ndef t_INITIAL_YFUNC_PA(t):\n    r\"\\(\"\n    return t\ndef t_CODE_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('CODE')\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_YFUNC_PA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_INITIAL_YFUNC_PA(t):\n    r\"\\(\"\n    return t\ndef t_CODE_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_INITIAL_YFUNC_PF(t):\n    r\"\\)\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_CODE_PA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_CODE_PA(t):\n    r\"\\(\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_INITIAL_YFUNC_PF(t):\n    r\"\\)\"\n    return t\ndef t_CODE_PF(t):\n    r\"\\)\"\n    t.lexer.pop_state()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_YFUNC_PF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_INITIAL_YFUNC_PF(t):\n    r\"\\)\"\n    return t\ndef t_CODE_PF(t):\n    r\"\\)\"\n    t.lexer.pop_state()\n    return t\ndef t_PCA(t):\n    r\"{\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_CODE_PF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_CODE_PF(t):\n    r\"\\)\"\n    t.lexer.pop_state()\n    return t\ndef t_PCA(t):\n    r\"{\"\n    return t\ndef t_REGEX_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_PCA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_PCA(t):\n    r\"{\"\n    return t\ndef t_REGEX_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()\n    return t\ndef t_SYMBOLS_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_REGEX_PCA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_REGEX_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()\n    return t\ndef t_SYMBOLS_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()\n    t.lexer.push_state('CODE')\n    return t\ndef t_YFUNC_CODE_PCA(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_SYMBOLS_PCA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_SYMBOLS_PCA(t):\n    r\"{\"\n    t.lexer.pop_state()\n    t.lexer.push_state('CODE')\n    return t\ndef t_YFUNC_CODE_PCA(t):\n    r\"{\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_PCF(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_YFUNC_CODE_PCA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_YFUNC_CODE_PCA(t):\n    r\"{\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_PCF(t):\n    r\"}\"\n    return t\ndef t_CODE_PCF(t):\n    r\"}\"\n    t.lexer.pop_state()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_PCF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_PCF(t):\n    r\"}\"\n    return t\ndef t_CODE_PCF(t):\n    r\"}\"\n    t.lexer.pop_state()\n    return t\ndef t_PRA(t):\n    r\"\\[\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_CODE_PCF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_CODE_PCF(t):\n    r\"}\"\n    t.lexer.pop_state()\n    return t\ndef t_PRA(t):\n    r\"\\[\"\n    return t\ndef t_CODE_PRA(t):\n    r\"\\[\"\n    t.lexer.push_state('CODE')",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_PRA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_PRA(t):\n    r\"\\[\"\n    return t\ndef t_CODE_PRA(t):\n    r\"\\[\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_PRF(t):\n    r\"\\]\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_CODE_PRA",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_CODE_PRA(t):\n    r\"\\[\"\n    t.lexer.push_state('CODE')\n    return t\ndef t_PRF(t):\n    r\"\\]\"\n    return t\ndef t_CODE_PRF(t):\n    r\"\\]\"\n    t.lexer.pop_state()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_PRF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_PRF(t):\n    r\"\\]\"\n    return t\ndef t_CODE_PRF(t):\n    r\"\\]\"\n    t.lexer.pop_state()\n    return t\ndef t_DS(t):\n    r\":\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_CODE_PRF",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_CODE_PRF(t):\n    r\"\\]\"\n    t.lexer.pop_state()\n    return t\ndef t_DS(t):\n    r\":\"\n    return t\ndef t_REGEX_DS(t):\n    r\":\"\n    t.lexer.pop_state()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_DS",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_DS(t):\n    r\":\"\n    return t\ndef t_REGEX_DS(t):\n    r\":\"\n    t.lexer.pop_state()\n    return t\ndef t_GRAMMAR_DS(t):\n    r\":\"\n    t.lexer.push_state(\"SYMBOLS\")",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_REGEX_DS",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_REGEX_DS(t):\n    r\":\"\n    t.lexer.pop_state()\n    return t\ndef t_GRAMMAR_DS(t):\n    r\":\"\n    t.lexer.push_state(\"SYMBOLS\")\n    return t\ndef t_aspval(t):\n    r\"\\\"[^0-9\\n]+\\\"\" #TODO: \\\" tem de passar ",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_DS",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_GRAMMAR_DS(t):\n    r\":\"\n    t.lexer.push_state(\"SYMBOLS\")\n    return t\ndef t_aspval(t):\n    r\"\\\"[^0-9\\n]+\\\"\" #TODO: \\\" tem de passar \n    return t\ndef t_pelval(t):\n    r\"'[^']+'\" #TODO: \\' tem de passar\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_aspval",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_aspval(t):\n    r\"\\\"[^0-9\\n]+\\\"\" #TODO: \\\" tem de passar \n    return t\ndef t_pelval(t):\n    r\"'[^']+'\" #TODO: \\' tem de passar\n    return t\ndef t_CODE_cod(t):\n    r\"([^{}\\(\\)\\[\\]])+\" #TODO: \\( , \\) , \\{ , \\} , \\[ e \\] tem de passar \n    return t\ndef t_id(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_pelval",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_pelval(t):\n    r\"'[^']+'\" #TODO: \\' tem de passar\n    return t\ndef t_CODE_cod(t):\n    r\"([^{}\\(\\)\\[\\]])+\" #TODO: \\( , \\) , \\{ , \\} , \\[ e \\] tem de passar \n    return t\ndef t_id(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_GRAMMAR_nt(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_CODE_cod",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_CODE_cod(t):\n    r\"([^{}\\(\\)\\[\\]])+\" #TODO: \\( , \\) , \\{ , \\} , \\[ e \\] tem de passar \n    return t\ndef t_id(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_GRAMMAR_nt(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_SYMBOLS_symbol(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_id",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_id(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_GRAMMAR_nt(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_SYMBOLS_symbol(t):\n    r\"([A-Za-z]+)|('.')\" #TODO: '\\'' e '{' tem de passar\n    return t\ndef t_YFUNC_name(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_GRAMMAR_nt",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_GRAMMAR_nt(t):\n    r\"[A-Za-z]+\"\n    return t\ndef t_SYMBOLS_symbol(t):\n    r\"([A-Za-z]+)|('.')\" #TODO: '\\'' e '{' tem de passar\n    return t\ndef t_YFUNC_name(t):\n    r\"[A-Za-z]\\w*\"\n    return t\ndef t_REGEX_rgx(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_SYMBOLS_symbol",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_SYMBOLS_symbol(t):\n    r\"([A-Za-z]+)|('.')\" #TODO: '\\'' e '{' tem de passar\n    return t\ndef t_YFUNC_name(t):\n    r\"[A-Za-z]\\w*\"\n    return t\ndef t_REGEX_rgx(t):\n    r\"((\\\\:)|[^:])+\" #TODO: ver isto melhor\n    return t\ndef t_ANY_error(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_YFUNC_name",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_YFUNC_name(t):\n    r\"[A-Za-z]\\w*\"\n    return t\ndef t_REGEX_rgx(t):\n    r\"((\\\\:)|[^:])+\" #TODO: ver isto melhor\n    return t\ndef t_ANY_error(t):\n    print(f\"Illegal character '{t.value[0]}', [{t.lexer.lineno}]\")\n    t.lexer.skip(1)\nlexer = lex.lex()",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_REGEX_rgx",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_REGEX_rgx(t):\n    r\"((\\\\:)|[^:])+\" #TODO: ver isto melhor\n    return t\ndef t_ANY_error(t):\n    print(f\"Illegal character '{t.value[0]}', [{t.lexer.lineno}]\")\n    t.lexer.skip(1)\nlexer = lex.lex()\n\"\"\"\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_ANY_error",
        "kind": 2,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "def t_ANY_error(t):\n    print(f\"Illegal character '{t.value[0]}', [{t.lexer.lineno}]\")\n    t.lexer.skip(1)\nlexer = lex.lex()\n\"\"\"\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())\nfor token in lexer:\n    print(token)\n\"\"\"",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "states",
        "kind": 5,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "states = [('REGEX','exclusive'),('GRAMMAR','exclusive'),('CODE','exclusive'),('YFUNC','exclusive'),('SYMBOLS','exclusive')]\nliterals = ['=',',']\ntokens = [\"LEX\",\"LTS\",\"IG\",\"TKS\",\"LFUNC\",\n\"RT\",\"ER\",\"TVAL\",\"TYPE\",\"YACC\",\"PRCD\",\"LTRG\",\n\"GRM\",\"PREC\",\"YFUNCS\",\"DEF\",\"PA\",\"PF\",\n\"PCA\",\"PCF\",\"PRA\",\"PRF\",\"DS\",\n\"aspval\",\"pelval\",\"cod\",\"id\",\"nt\",\"symbol\",\"name\",\"rgx\"]\nt_INITIAL_REGEX_GRAMMAR_YFUNC_SYMBOLS_ignore = \" \\t\\n \"\nt_CODE_ignore = \" \"\ndef t_LEX(t):",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "literals",
        "kind": 5,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "literals = ['=',',']\ntokens = [\"LEX\",\"LTS\",\"IG\",\"TKS\",\"LFUNC\",\n\"RT\",\"ER\",\"TVAL\",\"TYPE\",\"YACC\",\"PRCD\",\"LTRG\",\n\"GRM\",\"PREC\",\"YFUNCS\",\"DEF\",\"PA\",\"PF\",\n\"PCA\",\"PCF\",\"PRA\",\"PRF\",\"DS\",\n\"aspval\",\"pelval\",\"cod\",\"id\",\"nt\",\"symbol\",\"name\",\"rgx\"]\nt_INITIAL_REGEX_GRAMMAR_YFUNC_SYMBOLS_ignore = \" \\t\\n \"\nt_CODE_ignore = \" \"\ndef t_LEX(t):\n    r'LEX:'",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "tokens = [\"LEX\",\"LTS\",\"IG\",\"TKS\",\"LFUNC\",\n\"RT\",\"ER\",\"TVAL\",\"TYPE\",\"YACC\",\"PRCD\",\"LTRG\",\n\"GRM\",\"PREC\",\"YFUNCS\",\"DEF\",\"PA\",\"PF\",\n\"PCA\",\"PCF\",\"PRA\",\"PRF\",\"DS\",\n\"aspval\",\"pelval\",\"cod\",\"id\",\"nt\",\"symbol\",\"name\",\"rgx\"]\nt_INITIAL_REGEX_GRAMMAR_YFUNC_SYMBOLS_ignore = \" \\t\\n \"\nt_CODE_ignore = \" \"\ndef t_LEX(t):\n    r'LEX:'\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_INITIAL_REGEX_GRAMMAR_YFUNC_SYMBOLS_ignore",
        "kind": 5,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "t_INITIAL_REGEX_GRAMMAR_YFUNC_SYMBOLS_ignore = \" \\t\\n \"\nt_CODE_ignore = \" \"\ndef t_LEX(t):\n    r'LEX:'\n    return t\ndef t_LTS(t):\n    r\"literals\"\n    return t\ndef t_IG(t):\n    r\"ignore\"",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "t_CODE_ignore",
        "kind": 5,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "t_CODE_ignore = \" \"\ndef t_LEX(t):\n    r'LEX:'\n    return t\ndef t_LTS(t):\n    r\"literals\"\n    return t\ndef t_IG(t):\n    r\"ignore\"\n    return t",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "lexer",
        "kind": 5,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "lexer = lex.lex()\n\"\"\"\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())\nfor token in lexer:\n    print(token)\n\"\"\"",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "file",
        "kind": 5,
        "importPath": "plysimple_limpo",
        "description": "plysimple_limpo",
        "peekOfCode": "file = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nlexer.input(file.read())\nfor token in lexer:\n    print(token)\n\"\"\"",
        "detail": "plysimple_limpo",
        "documentation": {}
    },
    {
        "label": "p_Ply",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Ply(p):\n    \"Ply : Lexer Yc\"\n    p[0] = p[1] + \"\\n\" + p[2]\ndef p_Lexer(p):\n    \"Lexer : LEX Literals Ignore Tokens Lfuncs Lerror\"\n    p[0] = p[2] + \"\\n\" + p[3] +\"\\n\" + p[4] + \"\\n\" + p[5] + \"\\n\" + p[6]\ndef p_Yc(p):\n    \"Yc : YACC Precedents Declarations Grammar Yfs\"\n    p[0] = p[2] + \"\\n\" + p[3] + \"\\n\" + p[4] + \"\\n\" + p[5]\ndef p_Grammar(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Lexer",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Lexer(p):\n    \"Lexer : LEX Literals Ignore Tokens Lfuncs Lerror\"\n    p[0] = p[2] + \"\\n\" + p[3] +\"\\n\" + p[4] + \"\\n\" + p[5] + \"\\n\" + p[6]\ndef p_Yc(p):\n    \"Yc : YACC Precedents Declarations Grammar Yfs\"\n    p[0] = p[2] + \"\\n\" + p[3] + \"\\n\" + p[4] + \"\\n\" + p[5]\ndef p_Grammar(p):\n    \"Grammar : GRM Productions\"\n    p[0] = p[2]\ndef p_Yfs(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Yc",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Yc(p):\n    \"Yc : YACC Precedents Declarations Grammar Yfs\"\n    p[0] = p[2] + \"\\n\" + p[3] + \"\\n\" + p[4] + \"\\n\" + p[5]\ndef p_Grammar(p):\n    \"Grammar : GRM Productions\"\n    p[0] = p[2]\ndef p_Yfs(p):\n    \"Yfs : YFUNCS Funcs\"\n    p[0] = p[2]\ndef p_Literals(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Grammar",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Grammar(p):\n    \"Grammar : GRM Productions\"\n    p[0] = p[2]\ndef p_Yfs(p):\n    \"Yfs : YFUNCS Funcs\"\n    p[0] = p[2]\ndef p_Literals(p):\n    \"Literals : LTS '=' aspval\"\n    p[3] = p[3][1:-1] #remove as aspas\n    lits = [char for char in p[3]] #transforma a string numa lista de chars",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Yfs",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Yfs(p):\n    \"Yfs : YFUNCS Funcs\"\n    p[0] = p[2]\ndef p_Literals(p):\n    \"Literals : LTS '=' aspval\"\n    p[3] = p[3][1:-1] #remove as aspas\n    lits = [char for char in p[3]] #transforma a string numa lista de chars\n    p[0] = \"literals = \" + str(lits)\ndef p_Literals_empty(p):\n    \"Literals : \"",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Literals",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Literals(p):\n    \"Literals : LTS '=' aspval\"\n    p[3] = p[3][1:-1] #remove as aspas\n    lits = [char for char in p[3]] #transforma a string numa lista de chars\n    p[0] = \"literals = \" + str(lits)\ndef p_Literals_empty(p):\n    \"Literals : \"\n    p[0] = \"\"\ndef p_Ignore(p):\n    \"Ignore : IG '=' aspval\"",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Literals_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Literals_empty(p):\n    \"Literals : \"\n    p[0] = \"\"\ndef p_Ignore(p):\n    \"Ignore : IG '=' aspval\"\n    p[0] = \"t_ignore = \" + p[3]\ndef p_Ignore_empty(p):\n    \"Ignore : \"\n    p[0] = \"\"\ndef p_Tokens(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Ignore",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Ignore(p):\n    \"Ignore : IG '=' aspval\"\n    p[0] = \"t_ignore = \" + p[3]\ndef p_Ignore_empty(p):\n    \"Ignore : \"\n    p[0] = \"\"\ndef p_Tokens(p):\n    \"Tokens : TKS '=' PRA Tokl PRF\"\n    p[0] = \"tokens = \" + str(p[4])\ndef p_Tokl(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Ignore_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Ignore_empty(p):\n    \"Ignore : \"\n    p[0] = \"\"\ndef p_Tokens(p):\n    \"Tokens : TKS '=' PRA Tokl PRF\"\n    p[0] = \"tokens = \" + str(p[4])\ndef p_Tokl(p):\n    \"Tokl : Tokl ',' pelval\"\n    p[0] = p[1] + [p[3][1:-1]]\ndef p_Tokl_single(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Tokens",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Tokens(p):\n    \"Tokens : TKS '=' PRA Tokl PRF\"\n    p[0] = \"tokens = \" + str(p[4])\ndef p_Tokl(p):\n    \"Tokl : Tokl ',' pelval\"\n    p[0] = p[1] + [p[3][1:-1]]\ndef p_Tokl_single(p):\n    \"Tokl : pelval\"\n    p[0] = [p[1][1:-1]]\ndef p_Lfuncs(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Tokl",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Tokl(p):\n    \"Tokl : Tokl ',' pelval\"\n    p[0] = p[1] + [p[3][1:-1]]\ndef p_Tokl_single(p):\n    \"Tokl : pelval\"\n    p[0] = [p[1][1:-1]]\ndef p_Lfuncs(p):\n    \"Lfuncs : Lfuncs Lfunc\"\n    p[0] = p[1] + \"\\n\" + p[2]\ndef p_Lfuncs_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Tokl_single",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Tokl_single(p):\n    \"Tokl : pelval\"\n    p[0] = [p[1][1:-1]]\ndef p_Lfuncs(p):\n    \"Lfuncs : Lfuncs Lfunc\"\n    p[0] = p[1] + \"\\n\" + p[2]\ndef p_Lfuncs_empty(p):\n    \"Lfuncs : \"\n    p[0] = \"\"\ndef p_Lfunc(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Lfuncs",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Lfuncs(p):\n    \"Lfuncs : Lfuncs Lfunc\"\n    p[0] = p[1] + \"\\n\" + p[2]\ndef p_Lfuncs_empty(p):\n    \"Lfuncs : \"\n    p[0] = \"\"\ndef p_Lfunc(p):\n    \"Lfunc : LFUNC rgx DS RT PA pelval ',' Tv PF \"\n    p[2] = re.sub(r'(\\\\:)',r':',p[2])\n    p[0] = \"def t_\" + p[6][1:-1] + \"(t):\\n\\tr'\" + p[2] + \"'\\n\" + p[8]",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Lfuncs_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Lfuncs_empty(p):\n    \"Lfuncs : \"\n    p[0] = \"\"\ndef p_Lfunc(p):\n    \"Lfunc : LFUNC rgx DS RT PA pelval ',' Tv PF \"\n    p[2] = re.sub(r'(\\\\:)',r':',p[2])\n    p[0] = \"def t_\" + p[6][1:-1] + \"(t):\\n\\tr'\" + p[2] + \"'\\n\" + p[8]\ndef p_Tv(p):\n    \"Tv : TVAL\"\n    p[0] = \"\\treturn t\"",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Lfunc",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Lfunc(p):\n    \"Lfunc : LFUNC rgx DS RT PA pelval ',' Tv PF \"\n    p[2] = re.sub(r'(\\\\:)',r':',p[2])\n    p[0] = \"def t_\" + p[6][1:-1] + \"(t):\\n\\tr'\" + p[2] + \"'\\n\" + p[8]\ndef p_Tv(p):\n    \"Tv : TVAL\"\n    p[0] = \"\\treturn t\"\ndef p_Tv_type(p):\n    \"Tv : TYPE PA TVAL PF\"\n    p[0] = \"\\tt.value = \" + p[1] + \"(t.value)\\n\\treturn t\"",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Tv",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Tv(p):\n    \"Tv : TVAL\"\n    p[0] = \"\\treturn t\"\ndef p_Tv_type(p):\n    \"Tv : TYPE PA TVAL PF\"\n    p[0] = \"\\tt.value = \" + p[1] + \"(t.value)\\n\\treturn t\"\ndef p_Lerror(p):\n    \"Lerror : ER Codes PF\" #o lexer n está a apanhar tudo para o ER,rever\n    p[0] = \"def t_error(t):\\n\\tprintf(\" + p[2] + \")\"\ndef p_Lerror_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Tv_type",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Tv_type(p):\n    \"Tv : TYPE PA TVAL PF\"\n    p[0] = \"\\tt.value = \" + p[1] + \"(t.value)\\n\\treturn t\"\ndef p_Lerror(p):\n    \"Lerror : ER Codes PF\" #o lexer n está a apanhar tudo para o ER,rever\n    p[0] = \"def t_error(t):\\n\\tprintf(\" + p[2] + \")\"\ndef p_Lerror_empty(p):\n    \"Lerror : \"\n    p[0] = 'def t_ANY_error(t):\\n\\tprint(f\"Illegal character \\'{t.value[0]}\\', [{t.lexer.lineno}]\")\\n\\tt.lexer.skip(1)'\ndef p_Precedents(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Lerror",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Lerror(p):\n    \"Lerror : ER Codes PF\" #o lexer n está a apanhar tudo para o ER,rever\n    p[0] = \"def t_error(t):\\n\\tprintf(\" + p[2] + \")\"\ndef p_Lerror_empty(p):\n    \"Lerror : \"\n    p[0] = 'def t_ANY_error(t):\\n\\tprint(f\"Illegal character \\'{t.value[0]}\\', [{t.lexer.lineno}]\")\\n\\tt.lexer.skip(1)'\ndef p_Precedents(p):\n    \"Precedents : PRCD '=' PRA Prcdlist PRF\"\n    p[0] = \"precedent = [\" + p[4] + \"]\"\ndef p_Declarations(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Lerror_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Lerror_empty(p):\n    \"Lerror : \"\n    p[0] = 'def t_ANY_error(t):\\n\\tprint(f\"Illegal character \\'{t.value[0]}\\', [{t.lexer.lineno}]\")\\n\\tt.lexer.skip(1)'\ndef p_Precedents(p):\n    \"Precedents : PRCD '=' PRA Prcdlist PRF\"\n    p[0] = \"precedent = [\" + p[4] + \"]\"\ndef p_Declarations(p):\n    \"Declarations : Declarations Declaration\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Declarations_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Precedents",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Precedents(p):\n    \"Precedents : PRCD '=' PRA Prcdlist PRF\"\n    p[0] = \"precedent = [\" + p[4] + \"]\"\ndef p_Declarations(p):\n    \"Declarations : Declarations Declaration\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Declarations_empty(p):\n    \"Declarations : \"\n    p[0] = \"\"\ndef p_Declaration(p): #TODO: ver o que fazer com isto",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Declarations",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Declarations(p):\n    \"Declarations : Declarations Declaration\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Declarations_empty(p):\n    \"Declarations : \"\n    p[0] = \"\"\ndef p_Declaration(p): #TODO: ver o que fazer com isto\n    \"Declaration : id '=' P\"\n    p[0] = p[1] + \"=\" + p[3]\ndef p_Productions(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Declarations_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Declarations_empty(p):\n    \"Declarations : \"\n    p[0] = \"\"\ndef p_Declaration(p): #TODO: ver o que fazer com isto\n    \"Declaration : id '=' P\"\n    p[0] = p[1] + \"=\" + p[3]\ndef p_Productions(p):\n    \"Productions : Productions Production\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Productions_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Declaration",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Declaration(p): #TODO: ver o que fazer com isto\n    \"Declaration : id '=' P\"\n    p[0] = p[1] + \"=\" + p[3]\ndef p_Productions(p):\n    \"Productions : Productions Production\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Productions_empty(p):\n    \"Productions : \"\n    p[0] = \"\"\ndef p_Production(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Productions",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Productions(p):\n    \"Productions : Productions Production\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Productions_empty(p):\n    \"Productions : \"\n    p[0] = \"\"\ndef p_Production(p):\n    \"Production : nt DS Symbols PCA Codes PCF\"\n    p[0] = p[1] + \":\" + p[3] + \"{\" + p[5] + \"}\"\ndef p_Symbols(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Productions_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Productions_empty(p):\n    \"Productions : \"\n    p[0] = \"\"\ndef p_Production(p):\n    \"Production : nt DS Symbols PCA Codes PCF\"\n    p[0] = p[1] + \":\" + p[3] + \"{\" + p[5] + \"}\"\ndef p_Symbols(p):\n    \"Symbols : Symbols S\"\n    p[0] = p[1] + p[2] + \" \"\ndef p_Symbols_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Production",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Production(p):\n    \"Production : nt DS Symbols PCA Codes PCF\"\n    p[0] = p[1] + \":\" + p[3] + \"{\" + p[5] + \"}\"\ndef p_Symbols(p):\n    \"Symbols : Symbols S\"\n    p[0] = p[1] + p[2] + \" \"\ndef p_Symbols_empty(p):\n    \"Symbols : \"\n    p[0] = \"\"\ndef p_S(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Symbols",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Symbols(p):\n    \"Symbols : Symbols S\"\n    p[0] = p[1] + p[2] + \" \"\ndef p_Symbols_empty(p):\n    \"Symbols : \"\n    p[0] = \"\"\ndef p_S(p):\n    \"S : symbol\"\n    p[0] = p[1]\ndef p_S_Prec(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Symbols_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Symbols_empty(p):\n    \"Symbols : \"\n    p[0] = \"\"\ndef p_S(p):\n    \"S : symbol\"\n    p[0] = p[1]\ndef p_S_Prec(p):\n    \"S : PREC symbol\"\n    p[0] = \"%prec \" + p[2]\ndef p_P_pr(p): #TODO: ver o que fazer com isto",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_S",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_S(p):\n    \"S : symbol\"\n    p[0] = p[1]\ndef p_S_Prec(p):\n    \"S : PREC symbol\"\n    p[0] = \"%prec \" + p[2]\ndef p_P_pr(p): #TODO: ver o que fazer com isto\n    \"P : PRA PRF\"\n    p[0] = \"[]\"\ndef p_P_pc(p): #TODO: ver o que fazer com isto",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_S_Prec",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_S_Prec(p):\n    \"S : PREC symbol\"\n    p[0] = \"%prec \" + p[2]\ndef p_P_pr(p): #TODO: ver o que fazer com isto\n    \"P : PRA PRF\"\n    p[0] = \"[]\"\ndef p_P_pc(p): #TODO: ver o que fazer com isto\n    \"P : PCA PCF\"\n    p[0] = \"{}\"\ndef p_Prcdlist(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_P_pr",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_P_pr(p): #TODO: ver o que fazer com isto\n    \"P : PRA PRF\"\n    p[0] = \"[]\"\ndef p_P_pc(p): #TODO: ver o que fazer com isto\n    \"P : PCA PCF\"\n    p[0] = \"{}\"\ndef p_Prcdlist(p):\n    \"Prcdlist : Prcdlist PA LTRG ',' Pelvals pelval PF ','\"\n    p[0] = p[1] + \"(\" + p[3] + \",\" + p[5] + p[6] + \"),\"\ndef p_Prcdlist_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_P_pc",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_P_pc(p): #TODO: ver o que fazer com isto\n    \"P : PCA PCF\"\n    p[0] = \"{}\"\ndef p_Prcdlist(p):\n    \"Prcdlist : Prcdlist PA LTRG ',' Pelvals pelval PF ','\"\n    p[0] = p[1] + \"(\" + p[3] + \",\" + p[5] + p[6] + \"),\"\ndef p_Prcdlist_empty(p):\n    \"Prcdlist : \"\n    p[0] = \"\"\ndef p_Pelvals(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Prcdlist",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Prcdlist(p):\n    \"Prcdlist : Prcdlist PA LTRG ',' Pelvals pelval PF ','\"\n    p[0] = p[1] + \"(\" + p[3] + \",\" + p[5] + p[6] + \"),\"\ndef p_Prcdlist_empty(p):\n    \"Prcdlist : \"\n    p[0] = \"\"\ndef p_Pelvals(p):\n    \"Pelvals : Pelvals pelval ','\"\n    p[0] = p[1] + p[2] + ','\ndef p_Pelvals_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Prcdlist_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Prcdlist_empty(p):\n    \"Prcdlist : \"\n    p[0] = \"\"\ndef p_Pelvals(p):\n    \"Pelvals : Pelvals pelval ','\"\n    p[0] = p[1] + p[2] + ','\ndef p_Pelvals_empty(p):\n    \"Pelvals : \"\n    p[0] = \"\"\ndef p_Funcs(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Pelvals",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Pelvals(p):\n    \"Pelvals : Pelvals pelval ','\"\n    p[0] = p[1] + p[2] + ','\ndef p_Pelvals_empty(p):\n    \"Pelvals : \"\n    p[0] = \"\"\ndef p_Funcs(p):\n    \"Funcs : Funcs Func\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Funcs_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Pelvals_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Pelvals_empty(p):\n    \"Pelvals : \"\n    p[0] = \"\"\ndef p_Funcs(p):\n    \"Funcs : Funcs Func\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Funcs_empty(p):\n    \"Funcs : \"\n    p[0] = \"\"\ndef p_Func(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Funcs",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Funcs(p):\n    \"Funcs : Funcs Func\"\n    p[0] = p[1] + p[2] + \"\\n\"\ndef p_Funcs_empty(p):\n    \"Funcs : \"\n    p[0] = \"\"\ndef p_Func(p):\n    \"Func : DEF name PA name PF PCA Codes PCF\"\n    p[0] = \"def \" + p[2] + \"(\" + p[4] + \"):\" + p[7]\ndef p_Codes(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Funcs_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Funcs_empty(p):\n    \"Funcs : \"\n    p[0] = \"\"\ndef p_Func(p):\n    \"Func : DEF name PA name PF PCA Codes PCF\"\n    p[0] = \"def \" + p[2] + \"(\" + p[4] + \"):\" + p[7]\ndef p_Codes(p):\n    \"Codes : Codes Code\"\n    p[0] = p[1] + p[2]\ndef p_Codes_empty(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Func",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Func(p):\n    \"Func : DEF name PA name PF PCA Codes PCF\"\n    p[0] = \"def \" + p[2] + \"(\" + p[4] + \"):\" + p[7]\ndef p_Codes(p):\n    \"Codes : Codes Code\"\n    p[0] = p[1] + p[2]\ndef p_Codes_empty(p):\n    \"Codes : \"\n    p[0] = \"\"\ndef p_Code(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Codes",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Codes(p):\n    \"Codes : Codes Code\"\n    p[0] = p[1] + p[2]\ndef p_Codes_empty(p):\n    \"Codes : \"\n    p[0] = \"\"\ndef p_Code(p):\n    \"Code : cod\"\n    p[0] = p[1]\ndef p_Code_p(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Codes_empty",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Codes_empty(p):\n    \"Codes : \"\n    p[0] = \"\"\ndef p_Code(p):\n    \"Code : cod\"\n    p[0] = p[1]\ndef p_Code_p(p):\n    \"Code : PA Codes PF\"\n    p[0] = \"(\" + p[2] + \")\"\ndef p_Code_pr(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Code",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Code(p):\n    \"Code : cod\"\n    p[0] = p[1]\ndef p_Code_p(p):\n    \"Code : PA Codes PF\"\n    p[0] = \"(\" + p[2] + \")\"\ndef p_Code_pr(p):\n    \"Code : PRA Codes PRF\"\n    p[0] = \"[\" + p[2] + \"]\"\ndef p_Code_pc(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Code_p",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Code_p(p):\n    \"Code : PA Codes PF\"\n    p[0] = \"(\" + p[2] + \")\"\ndef p_Code_pr(p):\n    \"Code : PRA Codes PRF\"\n    p[0] = \"[\" + p[2] + \"]\"\ndef p_Code_pc(p):\n    \"Code : PCA Codes PCF\"\n    p[0] = \"{\" + p[2] + \"}\"\ndef p_error(p):",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Code_pr",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Code_pr(p):\n    \"Code : PRA Codes PRF\"\n    p[0] = \"[\" + p[2] + \"]\"\ndef p_Code_pc(p):\n    \"Code : PCA Codes PCF\"\n    p[0] = \"{\" + p[2] + \"}\"\ndef p_error(p):\n    print('Erro sintático: ', p)\n    parser.success = False\n# Build the parser",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_Code_pc",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_Code_pc(p):\n    \"Code : PCA Codes PCF\"\n    p[0] = \"{\" + p[2] + \"}\"\ndef p_error(p):\n    print('Erro sintático: ', p)\n    parser.success = False\n# Build the parser\nparser = yacc.yacc()\nimport sys\nparser.success = True",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "p_error",
        "kind": 2,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "def p_error(p):\n    print('Erro sintático: ', p)\n    parser.success = False\n# Build the parser\nparser = yacc.yacc()\nimport sys\nparser.success = True\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nprogram = file.read()\ncodigo = parser.parse(program)",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "parser",
        "kind": 5,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "parser = yacc.yacc()\nimport sys\nparser.success = True\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nprogram = file.read()\ncodigo = parser.parse(program)\nif parser.success:\n    print(\"Programa estruturalmente correto!\")\n    print(codigo)\nelse:",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "parser.success",
        "kind": 5,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "parser.success = True\nfile = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nprogram = file.read()\ncodigo = parser.parse(program)\nif parser.success:\n    print(\"Programa estruturalmente correto!\")\n    print(codigo)\nelse:\n    print(\"Programa com erros... Corrija e tente novamente!\")",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "file",
        "kind": 5,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "file = open(\"t.txt\",\"r\",encoding=\"utf-8\",errors=\"surrogateescape\")\nprogram = file.read()\ncodigo = parser.parse(program)\nif parser.success:\n    print(\"Programa estruturalmente correto!\")\n    print(codigo)\nelse:\n    print(\"Programa com erros... Corrija e tente novamente!\")",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "program",
        "kind": 5,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "program = file.read()\ncodigo = parser.parse(program)\nif parser.success:\n    print(\"Programa estruturalmente correto!\")\n    print(codigo)\nelse:\n    print(\"Programa com erros... Corrija e tente novamente!\")",
        "detail": "plysimple_sin",
        "documentation": {}
    },
    {
        "label": "codigo",
        "kind": 5,
        "importPath": "plysimple_sin",
        "description": "plysimple_sin",
        "peekOfCode": "codigo = parser.parse(program)\nif parser.success:\n    print(\"Programa estruturalmente correto!\")\n    print(codigo)\nelse:\n    print(\"Programa com erros... Corrija e tente novamente!\")",
        "detail": "plysimple_sin",
        "documentation": {}
    }
]