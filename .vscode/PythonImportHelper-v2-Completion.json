[
    {
        "label": "generators",
        "importPath": "__future__",
        "description": "__future__",
        "isExtraImport": true,
        "detail": "__future__",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "copy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "copy",
        "description": "copy",
        "detail": "copy",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "os.path",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os.path",
        "description": "os.path",
        "detail": "os.path",
        "documentation": {}
    },
    {
        "label": "types",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "types",
        "description": "types",
        "detail": "types",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "inspect",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "inspect",
        "description": "inspect",
        "detail": "inspect",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "statistics",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "statistics",
        "description": "statistics",
        "detail": "statistics",
        "documentation": {}
    },
    {
        "label": "ply.lex",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "platform",
        "description": "platform",
        "detail": "platform",
        "documentation": {}
    },
    {
        "label": "Macro",
        "kind": 6,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "class Macro(object):\n    def __init__(self,name,value,arglist=None,variadic=False):\n        self.name = name\n        self.value = value\n        self.arglist = arglist\n        self.variadic = variadic\n        if variadic:\n            self.vararg = arglist[-1]\n        self.source = None\n# ------------------------------------------------------------------",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "Preprocessor",
        "kind": 6,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "class Preprocessor(object):\n    def __init__(self,lexer=None):\n        if lexer is None:\n            lexer = lex.lexer\n        self.lexer = lexer\n        self.macros = { }\n        self.path = []\n        self.temp_path = []\n        # Probe the lexer for selected tokens\n        self.lexprobe()",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_WS",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_WS(t):\n    r'\\s+'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\nt_CPP_POUND = r'\\#'\nt_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "CPP_INTEGER",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_STRING",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Character constant 'c' or L'c'\ndef t_CPP_CHAR(t):\n    r'(L)?\\'([^\\\\\\n]|(\\\\(.|\\n)))*?\\''\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Comment",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_CHAR",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_CHAR(t):\n    r'(L)?\\'([^\\\\\\n]|(\\\\(.|\\n)))*?\\''\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Comment\ndef t_CPP_COMMENT1(t):\n    r'(/\\*(.|\\n)*?\\*/)'\n    ncr = t.value.count(\"\\n\")\n    t.lexer.lineno += ncr\n    # replace with one space or a number of '\\n'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_COMMENT1",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_COMMENT1(t):\n    r'(/\\*(.|\\n)*?\\*/)'\n    ncr = t.value.count(\"\\n\")\n    t.lexer.lineno += ncr\n    # replace with one space or a number of '\\n'\n    t.type = 'CPP_WS'; t.value = '\\n' * ncr if ncr else ' '\n    return t\n# Line comment\ndef t_CPP_COMMENT2(t):\n    r'(//.*?(\\n|$))'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_COMMENT2",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_CPP_COMMENT2(t):\n    r'(//.*?(\\n|$))'\n    # replace with '/n'\n    t.type = 'CPP_WS'; t.value = '\\n'\n    return t\ndef t_error(t):\n    t.type = t.value[0]\n    t.value = t.value[0]\n    t.lexer.skip(1)\n    return t",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_error",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def t_error(t):\n    t.type = t.value[0]\n    t.value = t.value[0]\n    t.lexer.skip(1)\n    return t\nimport re\nimport copy\nimport time\nimport os.path\n# -----------------------------------------------------------------------------",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "trigraph",
        "kind": 2,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "def trigraph(input):\n    return _trigraph_pat.sub(lambda g: _trigraph_rep[g.group()[-1]],input)\n# ------------------------------------------------------------------\n# Macro object\n#\n# This object holds information about preprocessor macros\n#\n#    .name      - Macro name (string)\n#    .value     - Macro value (a list of tokens)\n#    .arglist   - List of argument names",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "tokens = (\n   'CPP_ID','CPP_INTEGER', 'CPP_FLOAT', 'CPP_STRING', 'CPP_CHAR', 'CPP_WS', 'CPP_COMMENT1', 'CPP_COMMENT2', 'CPP_POUND','CPP_DPOUND'\n)\nliterals = \"+-*/%|&~^<>=!?()[]{}.,;:\\\\\\'\\\"\"\n# Whitespace\ndef t_CPP_WS(t):\n    r'\\s+'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\nt_CPP_POUND = r'\\#'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "literals",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "literals = \"+-*/%|&~^<>=!?()[]{}.,;:\\\\\\'\\\"\"\n# Whitespace\ndef t_CPP_WS(t):\n    r'\\s+'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\nt_CPP_POUND = r'\\#'\nt_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_POUND",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_POUND = r'\\#'\nt_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_DPOUND",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_DPOUND = r'\\#\\#'\n# Identifier\nt_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_ID",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_ID = r'[A-Za-z_][\\w_]*'\n# Integer literal\ndef CPP_INTEGER(t):\n    r'(((((0x)|(0X))[0-9a-fA-F]+)|(\\d+))([uU][lL]|[lL][uU]|[uU]|[lL])?)'\n    return t\nt_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_INTEGER",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_INTEGER = CPP_INTEGER\n# Floating literal\nt_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Character constant 'c' or L'c'\ndef t_CPP_CHAR(t):",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_CPP_FLOAT",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "t_CPP_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\ndef t_CPP_STRING(t):\n    r'\\\"([^\\\\\\n]|(\\\\(.|\\n)))*?\\\"'\n    t.lexer.lineno += t.value.count(\"\\n\")\n    return t\n# Character constant 'c' or L'c'\ndef t_CPP_CHAR(t):\n    r'(L)?\\'([^\\\\\\n]|(\\\\(.|\\n)))*?\\''\n    t.lexer.lineno += t.value.count(\"\\n\")",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "_trigraph_pat",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "_trigraph_pat = re.compile(r'''\\?\\?[=/\\'\\(\\)\\!<>\\-]''')\n_trigraph_rep = {\n    '=':'#',\n    '/':'\\\\',\n    \"'\":'^',\n    '(':'[',\n    ')':']',\n    '!':'|',\n    '<':'{',\n    '>':'}',",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "_trigraph_rep",
        "kind": 5,
        "importPath": "ply.cpp",
        "description": "ply.cpp",
        "peekOfCode": "_trigraph_rep = {\n    '=':'#',\n    '/':'\\\\',\n    \"'\":'^',\n    '(':'[',\n    ')':']',\n    '!':'|',\n    '<':'{',\n    '>':'}',\n    '-':'~'",
        "detail": "ply.cpp",
        "documentation": {}
    },
    {
        "label": "t_COMMENT",
        "kind": 2,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "def t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t\n# Comment (C++-Style)\ndef t_CPPCOMMENT(t):\n    r'//.*\\n'\n    t.lexer.lineno += 1\n    return t",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_CPPCOMMENT",
        "kind": 2,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "def t_CPPCOMMENT(t):\n    r'//.*\\n'\n    t.lexer.lineno += 1\n    return t",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "tokens = [\n    # Literals (identifier, integer constant, float constant, string constant, char const)\n    'ID', 'TYPEID', 'INTEGER', 'FLOAT', 'STRING', 'CHARACTER',\n    # Operators (+,-,*,/,%,|,&,~,^,<<,>>, ||, &&, !, <, <=, >, >=, ==, !=)\n    'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'MODULO',\n    'OR', 'AND', 'NOT', 'XOR', 'LSHIFT', 'RSHIFT',\n    'LOR', 'LAND', 'LNOT',\n    'LT', 'LE', 'GT', 'GE', 'EQ', 'NE',\n    # Assignment (=, *=, /=, %=, +=, -=, <<=, >>=, &=, ^=, |=)\n    'EQUALS', 'TIMESEQUAL', 'DIVEQUAL', 'MODEQUAL', 'PLUSEQUAL', 'MINUSEQUAL',",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_ID",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_ID = r'[A-Za-z_][A-Za-z0-9_]*'\n# Integer literal\nt_INTEGER = r'\\d+([uU]|[lL]|[uU][lL]|[lL][uU])?'\n# Floating literal\nt_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\nt_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_INTEGER",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_INTEGER = r'\\d+([uU]|[lL]|[uU][lL]|[lL][uU])?'\n# Floating literal\nt_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\nt_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_FLOAT",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_FLOAT = r'((\\d+)(\\.\\d+)(e(\\+|-)?(\\d+))? | (\\d+)e(\\+|-)?(\\d+))([lL]|[fF])?'\n# String literal\nt_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_STRING",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_STRING = r'\\\"([^\\\\\\n]|(\\\\.))*?\\\"'\n# Character constant 'c' or L'c'\nt_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t\n# Comment (C++-Style)\ndef t_CPPCOMMENT(t):",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "t_CHARACTER",
        "kind": 5,
        "importPath": "ply.ctokens",
        "description": "ply.ctokens",
        "peekOfCode": "t_CHARACTER = r'(L)?\\'([^\\\\\\n]|(\\\\.))*?\\''\n# Comment (C-Style)\ndef t_COMMENT(t):\n    r'/\\*(.|\\n)*?\\*/'\n    t.lexer.lineno += t.value.count('\\n')\n    return t\n# Comment (C++-Style)\ndef t_CPPCOMMENT(t):\n    r'//.*\\n'\n    t.lexer.lineno += 1",
        "detail": "ply.ctokens",
        "documentation": {}
    },
    {
        "label": "LexError",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class LexError(Exception):\n    def __init__(self, message, s):\n        self.args = (message,)\n        self.text = s\n# Token class.  This class is used to represent the tokens produced.\nclass LexToken(object):\n    def __str__(self):\n        return 'LexToken(%s,%r,%d,%d)' % (self.type, self.value, self.lineno, self.lexpos)\n    def __repr__(self):\n        return str(self)",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "LexToken",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class LexToken(object):\n    def __str__(self):\n        return 'LexToken(%s,%r,%d,%d)' % (self.type, self.value, self.lineno, self.lexpos)\n    def __repr__(self):\n        return str(self)\n# This object is a stand-in for a logging object created by the\n# logging module.\nclass PlyLogger(object):\n    def __init__(self, f):\n        self.f = f",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "PlyLogger",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class PlyLogger(object):\n    def __init__(self, f):\n        self.f = f\n    def critical(self, msg, *args, **kwargs):\n        self.f.write((msg % args) + '\\n')\n    def warning(self, msg, *args, **kwargs):\n        self.f.write('WARNING: ' + (msg % args) + '\\n')\n    def error(self, msg, *args, **kwargs):\n        self.f.write('ERROR: ' + (msg % args) + '\\n')\n    info = critical",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "NullLogger",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class NullLogger(object):\n    def __getattribute__(self, name):\n        return self\n    def __call__(self, *args, **kwargs):\n        return self\n# -----------------------------------------------------------------------------\n#                        === Lexing Engine ===\n#\n# The following Lexer class implements the lexer runtime.   There are only\n# a few public methods and attributes:",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "Lexer",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class Lexer:\n    def __init__(self):\n        self.lexre = None             # Master regular expression. This is a list of\n                                      # tuples (re, findex) where re is a compiled\n                                      # regular expression and findex is a list\n                                      # mapping regex group numbers to rules\n        self.lexretext = None         # Current regular expression strings\n        self.lexstatere = {}          # Dictionary mapping lexer states to master regexs\n        self.lexstateretext = {}      # Dictionary mapping lexer states to regex strings\n        self.lexstaterenames = {}     # Dictionary mapping lexer states to symbol names",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "LexerReflect",
        "kind": 6,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "class LexerReflect(object):\n    def __init__(self, ldict, log=None, reflags=0):\n        self.ldict      = ldict\n        self.error_func = None\n        self.tokens     = []\n        self.reflags    = reflags\n        self.stateinfo  = {'INITIAL': 'inclusive'}\n        self.modules    = set()\n        self.error      = False\n        self.log        = PlyLogger(sys.stderr) if log is None else log",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "get_caller_module_dict",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def get_caller_module_dict(levels):\n    f = sys._getframe(levels)\n    ldict = f.f_globals.copy()\n    if f.f_globals != f.f_locals:\n        ldict.update(f.f_locals)\n    return ldict\n# -----------------------------------------------------------------------------\n# _funcs_to_names()\n#\n# Given a list of regular expression functions, this converts it to a list",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "lex",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def lex(module=None, object=None, debug=False, optimize=False, lextab='lextab',\n        reflags=int(re.VERBOSE), nowarn=False, outputdir=None, debuglog=None, errorlog=None):\n    if lextab is None:\n        lextab = 'lextab'\n    global lexer\n    ldict = None\n    stateinfo  = {'INITIAL': 'inclusive'}\n    lexobj = Lexer()\n    lexobj.lexoptimize = optimize\n    global token, input",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "runmain",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def runmain(lexer=None, data=None):\n    if not data:\n        try:\n            filename = sys.argv[1]\n            f = open(filename)\n            data = f.read()\n            f.close()\n        except IndexError:\n            sys.stdout.write('Reading from standard input (type EOF to end):\\n')\n            data = sys.stdin.read()",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "TOKEN",
        "kind": 2,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "def TOKEN(r):\n    def set_regex(f):\n        if hasattr(r, '__call__'):\n            f.regex = _get_regex(r)\n        else:\n            f.regex = r\n        return f\n    return set_regex\n# Alternative spelling of the TOKEN decorator\nToken = TOKEN",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "__tabversion__",
        "kind": 5,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "__tabversion__ = '3.10'\nimport re\nimport sys\nimport types\nimport copy\nimport os\nimport inspect\n# This tuple contains known string types\ntry:\n    # Python 2.6",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "_is_identifier",
        "kind": 5,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "_is_identifier = re.compile(r'^[a-zA-Z0-9_]+$')\n# Exception thrown when invalid token encountered and no default error\n# handler is defined.\nclass LexError(Exception):\n    def __init__(self, message, s):\n        self.args = (message,)\n        self.text = s\n# Token class.  This class is used to represent the tokens produced.\nclass LexToken(object):\n    def __str__(self):",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "Token",
        "kind": 5,
        "importPath": "ply.lex",
        "description": "ply.lex",
        "peekOfCode": "Token = TOKEN",
        "detail": "ply.lex",
        "documentation": {}
    },
    {
        "label": "PlyLogger",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class PlyLogger(object):\n    def __init__(self, f):\n        self.f = f\n    def debug(self, msg, *args, **kwargs):\n        self.f.write((msg % args) + '\\n')\n    info = debug\n    def warning(self, msg, *args, **kwargs):\n        self.f.write('WARNING: ' + (msg % args) + '\\n')\n    def error(self, msg, *args, **kwargs):\n        self.f.write('ERROR: ' + (msg % args) + '\\n')",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "NullLogger",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class NullLogger(object):\n    def __getattribute__(self, name):\n        return self\n    def __call__(self, *args, **kwargs):\n        return self\n# Exception raised for yacc-related errors\nclass YaccError(Exception):\n    pass\n# Format the result message that the parser produces when running in debug mode.\ndef format_result(r):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "YaccError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class YaccError(Exception):\n    pass\n# Format the result message that the parser produces when running in debug mode.\ndef format_result(r):\n    repr_str = repr(r)\n    if '\\n' in repr_str:\n        repr_str = repr(repr_str)\n    if len(repr_str) > resultlimit:\n        repr_str = repr_str[:resultlimit] + ' ...'\n    result = '<%s @ 0x%x> (%s)' % (type(r).__name__, id(r), repr_str)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "YaccSymbol",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class YaccSymbol:\n    def __str__(self):\n        return self.type\n    def __repr__(self):\n        return str(self)\n# This class is a wrapper around the objects actually passed to each\n# grammar rule.   Index lookup and assignment actually assign the\n# .value attribute of the underlying YaccSymbol object.\n# The lineno() method returns the line number of a given\n# item (or 0 if not defined).   The linespan() method returns",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "YaccProduction",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class YaccProduction:\n    def __init__(self, s, stack=None):\n        self.slice = s\n        self.stack = stack\n        self.lexer = None\n        self.parser = None\n    def __getitem__(self, n):\n        if isinstance(n, slice):\n            return [s.value for s in self.slice[n]]\n        elif n >= 0:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRParser",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRParser:\n    def __init__(self, lrtab, errorf):\n        self.productions = lrtab.lr_productions\n        self.action = lrtab.lr_action\n        self.goto = lrtab.lr_goto\n        self.errorfunc = errorf\n        self.set_defaulted_states()\n        self.errorok = True\n    def errok(self):\n        self.errorok = True",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "Production",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class Production(object):\n    reduced = 0\n    def __init__(self, number, name, prod, precedence=('right', 0), func=None, file='', line=0):\n        self.name     = name\n        self.prod     = tuple(prod)\n        self.number   = number\n        self.func     = func\n        self.callable = None\n        self.file     = file\n        self.line     = line",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "MiniProduction",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class MiniProduction(object):\n    def __init__(self, str, name, len, func, file, line):\n        self.name     = name\n        self.len      = len\n        self.func     = func\n        self.callable = None\n        self.file     = file\n        self.line     = line\n        self.str      = str\n    def __str__(self):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRItem",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRItem(object):\n    def __init__(self, p, n):\n        self.name       = p.name\n        self.prod       = list(p.prod)\n        self.number     = p.number\n        self.lr_index   = n\n        self.lookaheads = {}\n        self.prod.insert(n, '.')\n        self.prod       = tuple(self.prod)\n        self.len        = len(self.prod)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "GrammarError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class GrammarError(YaccError):\n    pass\nclass Grammar(object):\n    def __init__(self, terminals):\n        self.Productions  = [None]  # A list of all of the productions.  The first\n                                    # entry is always reserved for the purpose of\n                                    # building an augmented grammar\n        self.Prodnames    = {}      # A dictionary mapping the names of nonterminals to a list of all\n                                    # productions of that nonterminal.\n        self.Prodmap      = {}      # A dictionary that is only used to detect duplicate",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "Grammar",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class Grammar(object):\n    def __init__(self, terminals):\n        self.Productions  = [None]  # A list of all of the productions.  The first\n                                    # entry is always reserved for the purpose of\n                                    # building an augmented grammar\n        self.Prodnames    = {}      # A dictionary mapping the names of nonterminals to a list of all\n                                    # productions of that nonterminal.\n        self.Prodmap      = {}      # A dictionary that is only used to detect duplicate\n                                    # productions.\n        self.Terminals    = {}      # A dictionary mapping the names of terminal symbols to a",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "VersionError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class VersionError(YaccError):\n    pass\nclass LRTable(object):\n    def __init__(self):\n        self.lr_action = None\n        self.lr_goto = None\n        self.lr_productions = None\n        self.lr_method = None\n    def read_table(self, module):\n        if isinstance(module, types.ModuleType):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRTable",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRTable(object):\n    def __init__(self):\n        self.lr_action = None\n        self.lr_goto = None\n        self.lr_productions = None\n        self.lr_method = None\n    def read_table(self, module):\n        if isinstance(module, types.ModuleType):\n            parsetab = module\n        else:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LALRError",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LALRError(YaccError):\n    pass\n# -----------------------------------------------------------------------------\n#                             == LRGeneratedTable ==\n#\n# This class implements the LR table generation algorithm.  There are no\n# public methods except for write()\n# -----------------------------------------------------------------------------\nclass LRGeneratedTable(LRTable):\n    def __init__(self, grammar, method='LALR', log=None):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "LRGeneratedTable",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class LRGeneratedTable(LRTable):\n    def __init__(self, grammar, method='LALR', log=None):\n        if method not in ['SLR', 'LALR']:\n            raise LALRError('Unsupported method %s' % method)\n        self.grammar = grammar\n        self.lr_method = method\n        # Set up the logger\n        if not log:\n            log = NullLogger()\n        self.log = log",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "ParserReflect",
        "kind": 6,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "class ParserReflect(object):\n    def __init__(self, pdict, log=None):\n        self.pdict      = pdict\n        self.start      = None\n        self.error_func = None\n        self.tokens     = None\n        self.modules    = set()\n        self.grammar    = []\n        self.error      = False\n        if log is None:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "format_result",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def format_result(r):\n    repr_str = repr(r)\n    if '\\n' in repr_str:\n        repr_str = repr(repr_str)\n    if len(repr_str) > resultlimit:\n        repr_str = repr_str[:resultlimit] + ' ...'\n    result = '<%s @ 0x%x> (%s)' % (type(r).__name__, id(r), repr_str)\n    return result\n# Format stack entries when the parser is running in debug mode\ndef format_stack_entry(r):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "format_stack_entry",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def format_stack_entry(r):\n    repr_str = repr(r)\n    if '\\n' in repr_str:\n        repr_str = repr(repr_str)\n    if len(repr_str) < 16:\n        return repr_str\n    else:\n        return '<%s @ 0x%x>' % (type(r).__name__, id(r))\n# Panic mode error recovery support.   This feature is being reworked--much of the\n# code here is to offer a deprecation/backwards compatible transition",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "errok",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def errok():\n    warnings.warn(_warnmsg)\n    return _errok()\ndef restart():\n    warnings.warn(_warnmsg)\n    return _restart()\ndef token():\n    warnings.warn(_warnmsg)\n    return _token()\n# Utility function to call the p_error() function with some deprecation hacks",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "restart",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def restart():\n    warnings.warn(_warnmsg)\n    return _restart()\ndef token():\n    warnings.warn(_warnmsg)\n    return _token()\n# Utility function to call the p_error() function with some deprecation hacks\ndef call_errorfunc(errorfunc, token, parser):\n    global _errok, _token, _restart\n    _errok = parser.errok",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "token",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def token():\n    warnings.warn(_warnmsg)\n    return _token()\n# Utility function to call the p_error() function with some deprecation hacks\ndef call_errorfunc(errorfunc, token, parser):\n    global _errok, _token, _restart\n    _errok = parser.errok\n    _token = parser.token\n    _restart = parser.restart\n    r = errorfunc(token)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "call_errorfunc",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def call_errorfunc(errorfunc, token, parser):\n    global _errok, _token, _restart\n    _errok = parser.errok\n    _token = parser.token\n    _restart = parser.restart\n    r = errorfunc(token)\n    try:\n        del _errok, _token, _restart\n    except NameError:\n        pass",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "rightmost_terminal",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def rightmost_terminal(symbols, terminals):\n    i = len(symbols) - 1\n    while i >= 0:\n        if symbols[i] in terminals:\n            return symbols[i]\n        i -= 1\n    return None\n# -----------------------------------------------------------------------------\n#                           === GRAMMAR CLASS ===\n#",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "digraph",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def digraph(X, R, FP):\n    N = {}\n    for x in X:\n        N[x] = 0\n    stack = []\n    F = {}\n    for x in X:\n        if N[x] == 0:\n            traverse(x, N, stack, F, X, R, FP)\n    return F",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "traverse",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def traverse(x, N, stack, F, X, R, FP):\n    stack.append(x)\n    d = len(stack)\n    N[x] = d\n    F[x] = FP(x)             # F(X) <- F'(x)\n    rel = R(x)               # Get y's related to x\n    for y in rel:\n        if N[y] == 0:\n            traverse(y, N, stack, F, X, R, FP)\n        N[x] = min(N[x], N[y])",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "get_caller_module_dict",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def get_caller_module_dict(levels):\n    f = sys._getframe(levels)\n    ldict = f.f_globals.copy()\n    if f.f_globals != f.f_locals:\n        ldict.update(f.f_locals)\n    return ldict\n# -----------------------------------------------------------------------------\n# parse_grammar()\n#\n# This takes a raw grammar rule string and parses it into production data",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "parse_grammar",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def parse_grammar(doc, file, line):\n    grammar = []\n    # Split the doc string into lines\n    pstrings = doc.splitlines()\n    lastp = None\n    dline = line\n    for ps in pstrings:\n        dline += 1\n        p = ps.split()\n        if not p:",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "yacc",
        "kind": 2,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "def yacc(method='LALR', debug=yaccdebug, module=None, tabmodule=tab_module, start=None,\n         check_recursion=True, optimize=False, write_tables=True, debugfile=debug_file,\n         outputdir=None, debuglog=None, errorlog=None, picklefile=None):\n    if tabmodule is None:\n        tabmodule = tab_module\n    # Reference to the parsing method of the last built parser\n    global parse\n    # If pickling is enabled, table files are not created\n    if picklefile:\n        write_tables = 0",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "__tabversion__",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "__tabversion__ = '3.10'\n#-----------------------------------------------------------------------------\n#                     === User configurable parameters ===\n#\n# Change these to modify the default behavior of yacc (if you wish)\n#-----------------------------------------------------------------------------\nyaccdebug   = True             # Debugging mode.  If set, yacc generates a\n                               # a 'parser.out' file in the current directory\ndebug_file  = 'parser.out'     # Default name of the debugging file\ntab_module  = 'parsetab'       # Default name of the table module",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "error_count",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "error_count = 3                # Number of symbols that must be shifted to leave recovery mode\nyaccdevel   = False            # Set to True if developing yacc.  This turns off optimized\n                               # implementations of certain functions.\nresultlimit = 40               # Size limit of results when running in debug mode.\npickle_protocol = 0            # Protocol to use when writing pickle files\n# String type-checking compatibility\nif sys.version_info[0] < 3:\n    string_types = basestring\nelse:\n    string_types = str",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "resultlimit",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "resultlimit = 40               # Size limit of results when running in debug mode.\npickle_protocol = 0            # Protocol to use when writing pickle files\n# String type-checking compatibility\nif sys.version_info[0] < 3:\n    string_types = basestring\nelse:\n    string_types = str\nMAXINT = sys.maxsize\n# This object is a stand-in for a logging object created by the\n# logging module.   PLY will use this by default to create things",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "pickle_protocol",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "pickle_protocol = 0            # Protocol to use when writing pickle files\n# String type-checking compatibility\nif sys.version_info[0] < 3:\n    string_types = basestring\nelse:\n    string_types = str\nMAXINT = sys.maxsize\n# This object is a stand-in for a logging object created by the\n# logging module.   PLY will use this by default to create things\n# such as the parser.out file.  If a user wants more detailed",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "MAXINT",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "MAXINT = sys.maxsize\n# This object is a stand-in for a logging object created by the\n# logging module.   PLY will use this by default to create things\n# such as the parser.out file.  If a user wants more detailed\n# information, they can create their own logging object and pass\n# it into PLY.\nclass PlyLogger(object):\n    def __init__(self, f):\n        self.f = f\n    def debug(self, msg, *args, **kwargs):",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_errok",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_errok = None\n_token = None\n_restart = None\n_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_token",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_token = None\n_restart = None\n_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()\n'''",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_restart",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_restart = None\n_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()\n'''\ndef errok():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_warnmsg",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_warnmsg = '''PLY: Don't use global functions errok(), token(), and restart() in p_error().\nInstead, invoke the methods on the associated parser instance:\n    def p_error(p):\n        ...\n        # Use parser.errok(), parser.token(), parser.restart()\n        ...\n    parser = yacc.yacc()\n'''\ndef errok():\n    warnings.warn(_warnmsg)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_is_identifier",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_is_identifier = re.compile(r'^[a-zA-Z0-9_-]+$')\n# -----------------------------------------------------------------------------\n# class Production:\n#\n# This class stores the raw information about a single production or grammar rule.\n# A grammar rule refers to a specification such as this:\n#\n#       expr : expr PLUS term\n#\n# Here are the basic attributes defined on all productions",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_tabversion",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_tabversion = %r\n_lr_method = %r\n_lr_signature = %r\n    ''' % (os.path.basename(filename), __tabversion__, self.lr_method, signature))\n            # Change smaller to 0 to go back to original tables\n            smaller = 1\n            # Factor out names to try and make smaller\n            if smaller:\n                items = {}\n                for s, nd in self.lr_action.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_method",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_method = %r\n_lr_signature = %r\n    ''' % (os.path.basename(filename), __tabversion__, self.lr_method, signature))\n            # Change smaller to 0 to go back to original tables\n            smaller = 1\n            # Factor out names to try and make smaller\n            if smaller:\n                items = {}\n                for s, nd in self.lr_action.items():\n                    for name, v in nd.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_signature",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_signature = %r\n    ''' % (os.path.basename(filename), __tabversion__, self.lr_method, signature))\n            # Change smaller to 0 to go back to original tables\n            smaller = 1\n            # Factor out names to try and make smaller\n            if smaller:\n                items = {}\n                for s, nd in self.lr_action.items():\n                    for name, v in nd.items():\n                        i = items.get(name)",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_action",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_action = {}\nfor _k, _v in _lr_action_items.items():\n   for _x,_y in zip(_v[0],_v[1]):\n      if not _x in _lr_action:  _lr_action[_x] = {}\n      _lr_action[_x][_k] = _y\ndel _lr_action_items\n''')\n            else:\n                f.write('\\n_lr_action = { ')\n                for k, v in self.lr_action.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "_lr_goto",
        "kind": 5,
        "importPath": "ply.yacc",
        "description": "ply.yacc",
        "peekOfCode": "_lr_goto = {}\nfor _k, _v in _lr_goto_items.items():\n   for _x, _y in zip(_v[0], _v[1]):\n       if not _x in _lr_goto: _lr_goto[_x] = {}\n       _lr_goto[_x][_k] = _y\ndel _lr_goto_items\n''')\n            else:\n                f.write('\\n_lr_goto = { ')\n                for k, v in self.lr_goto.items():",
        "detail": "ply.yacc",
        "documentation": {}
    },
    {
        "label": "get_source_range",
        "kind": 2,
        "importPath": "ply.ygen",
        "description": "ply.ygen",
        "peekOfCode": "def get_source_range(lines, tag):\n    srclines = enumerate(lines)\n    start_tag = '#--! %s-start' % tag\n    end_tag = '#--! %s-end' % tag\n    for start_index, line in srclines:\n        if line.strip().startswith(start_tag):\n            break\n    for end_index, line in srclines:\n        if line.strip().endswith(end_tag):\n            break",
        "detail": "ply.ygen",
        "documentation": {}
    },
    {
        "label": "filter_section",
        "kind": 2,
        "importPath": "ply.ygen",
        "description": "ply.ygen",
        "peekOfCode": "def filter_section(lines, tag):\n    filtered_lines = []\n    include = True\n    tag_text = '#--! %s' % tag\n    for line in lines:\n        if line.strip().startswith(tag_text):\n            include = not include\n        elif include:\n            filtered_lines.append(line)\n    return filtered_lines",
        "detail": "ply.ygen",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "ply.ygen",
        "description": "ply.ygen",
        "peekOfCode": "def main():\n    dirname = os.path.dirname(__file__)\n    shutil.copy2(os.path.join(dirname, 'yacc.py'), os.path.join(dirname, 'yacc.py.bak'))\n    with open(os.path.join(dirname, 'yacc.py'), 'r') as f:\n        lines = f.readlines()\n    parse_start, parse_end = get_source_range(lines, 'parsedebug')\n    parseopt_start, parseopt_end = get_source_range(lines, 'parseopt')\n    parseopt_notrack_start, parseopt_notrack_end = get_source_range(lines, 'parseopt-notrack')\n    # Get the original source\n    orig_lines = lines[parse_start:parse_end]",
        "detail": "ply.ygen",
        "documentation": {}
    },
    {
        "label": "str_to_lis",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def str_to_list (str):\n    return re.findall(r'[^\\n,]+',str)\n# funo que transforma uma string de nmeros numa soma\ndef str_to_sum (str):\n    return sum([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros na mdia\ndef str_to_media (str):\n    return statistics.mean([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa soma\ndef str_to_max (str):",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "str_to_su",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def str_to_sum (str):\n    return sum([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros na mdia\ndef str_to_media (str):\n    return statistics.mean([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa soma\ndef str_to_max (str):\n    return max([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa soma\ndef str_to_min (str):",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "str_to_medi",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def str_to_media (str):\n    return statistics.mean([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa soma\ndef str_to_max (str):\n    return max([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa soma\ndef str_to_min (str):\n    return min([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa lista com os seus quadrados\ndef str_to_quadrado (str):",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "str_to_ma",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def str_to_max (str):\n    return max([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa soma\ndef str_to_min (str):\n    return min([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa lista com os seus quadrados\ndef str_to_quadrado (str):\n    return ([pow(float(s),2) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que incrementa uma string\ndef increment_str(str):",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "str_to_mi",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def str_to_min (str):\n    return min([float(s) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que transforma uma string de nmeros numa lista com os seus quadrados\ndef str_to_quadrado (str):\n    return ([pow(float(s),2) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que incrementa uma string\ndef increment_str(str):\n    if(ord(str[0]) < 122):\n        str = chr(ord(str[0])+1) + str[1:]\n    else:",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "str_to_quadrad",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def str_to_quadrado (str):\n    return ([pow(float(s),2) for s in re.findall(r'(\\d+(?:\\.\\d+)?)',str)])\n# funo que incrementa uma string\ndef increment_str(str):\n    if(ord(str[0]) < 122):\n        str = chr(ord(str[0])+1) + str[1:]\n    else:\n        str = \"a\" + str[0:]\n    return str\n# funo que troca o nome de um ficheiro.csv para ficheiro.json",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "increment_str",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def increment_str(str):\n    if(ord(str[0]) < 122):\n        str = chr(ord(str[0])+1) + str[1:]\n    else:\n        str = \"a\" + str[0:]\n    return str\n# funo que troca o nome de um ficheiro.csv para ficheiro.json\ndef change_name(csv):\n    json = re.sub(r'(\\w+\\.)(CSV|csv)',r'\\1json',csv)\n    return json",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "change_name",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def change_name(csv):\n    json = re.sub(r'(\\w+\\.)(CSV|csv)',r'\\1json',csv)\n    return json\n#PLY\ntokens = [\"LISTFIELD\",\"SEPARATOR\",\"FIELD\"]\ndef t_LISTFIELD(t):\n    r'(([^\",]+)|(\"[^\"]+\"))\\{\\d+(,\\d+)?\\}(::\\w+)?'\n    m = re.match(r'(?P<nome>([^\",\\n]+)|(\\\"[^\"\\n]+\"))\\{(?P<min>\\d+)(,(?P<max>\\d+))?\\}(?P<funcao>::\\w+)?',t.value)\n    num = r'(\\d+(\\.\\d+)?)'\n    abc = r'([^\\n,]+)'",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "t_LISTFIELD",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def t_LISTFIELD(t):\n    r'(([^\",]+)|(\"[^\"]+\"))\\{\\d+(,\\d+)?\\}(::\\w+)?'\n    m = re.match(r'(?P<nome>([^\",\\n]+)|(\\\"[^\"\\n]+\"))\\{(?P<min>\\d+)(,(?P<max>\\d+))?\\}(?P<funcao>::\\w+)?',t.value)\n    num = r'(\\d+(\\.\\d+)?)'\n    abc = r'([^\\n,]+)'\n    t.value = m.group(\"nome\")\n    min = int(m.group(\"min\"))\n    max = min\n    if(m.group(\"max\")):\n        max = int(m.group(\"max\"))",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "t_FIELD",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def t_FIELD(t):\n    r'([^\",]+)|(\"[^\"]+\")'\n    regex = r'(?P<' + lexer.id + r'>([^\",\\n]+)|(\"[^\"\\n]+\"))?'\n    lexer.fields.append((lexer.id,\"\",t.value))\n    lexer.id = increment_str(lexer.id)\n    lexer.nfields+=1\n    lexer.regex+=regex\ndef t_SEPARATOR(t):\n    r','\n    if lexer.nlistcommas > 0:",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "t_SEPARATOR",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def t_SEPARATOR(t):\n    r','\n    if lexer.nlistcommas > 0:\n        lexer.nlistcommas-=1\n    else: \n        lexer.regex += r','\n        lexer.ncommas+=1\nt_ignore = \"\\n\"\ndef t_ANY_error(t):\n    print(\"Invalid Header in csv.\")",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "t_ANY_error",
        "kind": 2,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "def t_ANY_error(t):\n    print(\"Invalid Header in csv.\")\n    sys.exit()\nlexer = lex.lex()\nlexer.fields = []\nlexer.regex = r''\nlexer.id = \"a\"\nlexer.ncommas = 0\nlexer.nfields = 0\nlexer.nlistcommas = 0",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "platform",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "platform = platform.system()\nif platform == \"Linux\" or  platform ==\"Darwin\":\n    corr = 2\nelif platform == \"Windows\":\n    corr = 3\n# argumentos\nargs = sys.argv[1:] \n# verifica se recebeu 1 argumento\nlenargs = len(args)\nif lenargs != 1:",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "args",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "args = sys.argv[1:] \n# verifica se recebeu 1 argumento\nlenargs = len(args)\nif lenargs != 1:\n    print(\"number of arguments invalid! please give one argument.\")\n    sys.exit()\n# verifica se o argumento que recebeu  um .csv\nvalid = re.match(r'\\w+\\.(CSV|csv)$',args[0])\nif valid:\n    print(\"Loading \"+ args[0] +\"...\") ",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lenargs",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lenargs = len(args)\nif lenargs != 1:\n    print(\"number of arguments invalid! please give one argument.\")\n    sys.exit()\n# verifica se o argumento que recebeu  um .csv\nvalid = re.match(r'\\w+\\.(CSV|csv)$',args[0])\nif valid:\n    print(\"Loading \"+ args[0] +\"...\") \nelse: \n    print(\"invalid arguments!\")",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "valid",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "valid = re.match(r'\\w+\\.(CSV|csv)$',args[0])\nif valid:\n    print(\"Loading \"+ args[0] +\"...\") \nelse: \n    print(\"invalid arguments!\")\n    sys.exit()\n# funo que transforma uma string de nmeros numa lista\ndef str_to_list (str):\n    return re.findall(r'[^\\n,]+',str)\n# funo que transforma uma string de nmeros numa soma",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "tokens",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "tokens = [\"LISTFIELD\",\"SEPARATOR\",\"FIELD\"]\ndef t_LISTFIELD(t):\n    r'(([^\",]+)|(\"[^\"]+\"))\\{\\d+(,\\d+)?\\}(::\\w+)?'\n    m = re.match(r'(?P<nome>([^\",\\n]+)|(\\\"[^\"\\n]+\"))\\{(?P<min>\\d+)(,(?P<max>\\d+))?\\}(?P<funcao>::\\w+)?',t.value)\n    num = r'(\\d+(\\.\\d+)?)'\n    abc = r'([^\\n,]+)'\n    t.value = m.group(\"nome\")\n    min = int(m.group(\"min\"))\n    max = min\n    if(m.group(\"max\")):",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "t_ignore",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "t_ignore = \"\\n\"\ndef t_ANY_error(t):\n    print(\"Invalid Header in csv.\")\n    sys.exit()\nlexer = lex.lex()\nlexer.fields = []\nlexer.regex = r''\nlexer.id = \"a\"\nlexer.ncommas = 0\nlexer.nfields = 0",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lexer",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lexer = lex.lex()\nlexer.fields = []\nlexer.regex = r''\nlexer.id = \"a\"\nlexer.ncommas = 0\nlexer.nfields = 0\nlexer.nlistcommas = 0\nfile = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lexer.fields",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lexer.fields = []\nlexer.regex = r''\nlexer.id = \"a\"\nlexer.ncommas = 0\nlexer.nfields = 0\nlexer.nlistcommas = 0\nfile = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)\nfor tok in lexer:",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lexer.regex",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lexer.regex = r''\nlexer.id = \"a\"\nlexer.ncommas = 0\nlexer.nfields = 0\nlexer.nlistcommas = 0\nfile = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)\nfor tok in lexer:\n    pass",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lexer.id",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lexer.id = \"a\"\nlexer.ncommas = 0\nlexer.nfields = 0\nlexer.nlistcommas = 0\nfile = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)\nfor tok in lexer:\n    pass\n#verifica se o header  valido (numero de virgulas = numero de campos-1)",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lexer.ncommas",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lexer.ncommas = 0\nlexer.nfields = 0\nlexer.nlistcommas = 0\nfile = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)\nfor tok in lexer:\n    pass\n#verifica se o header  valido (numero de virgulas = numero de campos-1)\nif lexer.ncommas != lexer.nfields-1:",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lexer.nfields",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lexer.nfields = 0\nlexer.nlistcommas = 0\nfile = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)\nfor tok in lexer:\n    pass\n#verifica se o header  valido (numero de virgulas = numero de campos-1)\nif lexer.ncommas != lexer.nfields-1:\n    print(\"invalid header\")",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "lexer.nlistcommas",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "lexer.nlistcommas = 0\nfile = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)\nfor tok in lexer:\n    pass\n#verifica se o header  valido (numero de virgulas = numero de campos-1)\nif lexer.ncommas != lexer.nfields-1:\n    print(\"invalid header\")\n    sys.exit()",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "file",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "file = open(args[0],\"r\",encoding=\"utf-8\")\nheader = file.readline()\nlexer.input(header)\nfor tok in lexer:\n    pass\n#verifica se o header  valido (numero de virgulas = numero de campos-1)\nif lexer.ncommas != lexer.nfields-1:\n    print(\"invalid header\")\n    sys.exit()\n# tira a virgula final na expresso regular que o lexer mete a mais caso acabe numa LISTA",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "header",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "header = file.readline()\nlexer.input(header)\nfor tok in lexer:\n    pass\n#verifica se o header  valido (numero de virgulas = numero de campos-1)\nif lexer.ncommas != lexer.nfields-1:\n    print(\"invalid header\")\n    sys.exit()\n# tira a virgula final na expresso regular que o lexer mete a mais caso acabe numa LISTA\nif lexer.regex[-1] == \",\":",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "exp",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "exp = re.compile(lexer.regex)\n# lemos o resto do csv\ncontent = file.read()\n#Cria e abre o ficheiro .json\njson_filename = change_name(args[0])\nfpjson = open(json_filename,\"w+\",encoding=\"utf-8\")\nmos = exp.finditer(content) #fazer a lista de match objects que deram match com o resto do ficheiro\nprint(\"Creating \" + json_filename + \"...\")\n#Escreve o dicionrio no .json\nfpjson.write(\"[\\n\")",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "content",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "content = file.read()\n#Cria e abre o ficheiro .json\njson_filename = change_name(args[0])\nfpjson = open(json_filename,\"w+\",encoding=\"utf-8\")\nmos = exp.finditer(content) #fazer a lista de match objects que deram match com o resto do ficheiro\nprint(\"Creating \" + json_filename + \"...\")\n#Escreve o dicionrio no .json\nfpjson.write(\"[\\n\")\nfor mo in mos: #para cada match object vamos construir o dicionario\n    fpjson.write(\"  {\\n\")",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "json_filename",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "json_filename = change_name(args[0])\nfpjson = open(json_filename,\"w+\",encoding=\"utf-8\")\nmos = exp.finditer(content) #fazer a lista de match objects que deram match com o resto do ficheiro\nprint(\"Creating \" + json_filename + \"...\")\n#Escreve o dicionrio no .json\nfpjson.write(\"[\\n\")\nfor mo in mos: #para cada match object vamos construir o dicionario\n    fpjson.write(\"  {\\n\")\n    dict = mo.groupdict()\n    for header in lexer.fields:",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "fpjson",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "fpjson = open(json_filename,\"w+\",encoding=\"utf-8\")\nmos = exp.finditer(content) #fazer a lista de match objects que deram match com o resto do ficheiro\nprint(\"Creating \" + json_filename + \"...\")\n#Escreve o dicionrio no .json\nfpjson.write(\"[\\n\")\nfor mo in mos: #para cada match object vamos construir o dicionario\n    fpjson.write(\"  {\\n\")\n    dict = mo.groupdict()\n    for header in lexer.fields:\n            nomeProv = header[0]",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "mos",
        "kind": 5,
        "importPath": "csv_to_json",
        "description": "csv_to_json",
        "peekOfCode": "mos = exp.finditer(content) #fazer a lista de match objects que deram match com o resto do ficheiro\nprint(\"Creating \" + json_filename + \"...\")\n#Escreve o dicionrio no .json\nfpjson.write(\"[\\n\")\nfor mo in mos: #para cada match object vamos construir o dicionario\n    fpjson.write(\"  {\\n\")\n    dict = mo.groupdict()\n    for header in lexer.fields:\n            nomeProv = header[0]\n            funcao = header[1]",
        "detail": "csv_to_json",
        "documentation": {}
    },
    {
        "label": "xx",
        "kind": 5,
        "importPath": "teste",
        "description": "teste",
        "peekOfCode": "xx = \"guru99.,edu32cation is fun\"\nr1 = re.findall(r\"\\d+\\.\",xx)\nprint(r1)",
        "detail": "teste",
        "documentation": {}
    },
    {
        "label": "r1",
        "kind": 5,
        "importPath": "teste",
        "description": "teste",
        "peekOfCode": "r1 = re.findall(r\"\\d+\\.\",xx)\nprint(r1)",
        "detail": "teste",
        "documentation": {}
    }
]